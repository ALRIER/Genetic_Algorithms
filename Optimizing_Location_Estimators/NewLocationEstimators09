

# =========================== SETUP & PACKAGES ============================

required_packages <- c(
  "modeest",   # modos (hsm, parzen)
  "statmod",   # rinvgauss
  "gtools",    # rdirichlet
  "parallel",  # PSOCK cluster
  "MASS",      # rlm (Huber/Bisquare)
  "dplyr", "tibble", "readr"  # utilidades de datos
)

for (pkg in required_packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
  }
}
for (pkg in required_packages) {
  suppressPackageStartupMessages(library(pkg, character.only = TRUE))
}

# Small helper used later: x %||% y returns x if not NULL else y
`%||%` <- function(x, y) if (!is.null(x)) x else y

# =========================== WORKING DIRECTORY ===========================
setwd("C:/Users/AlvaroRivera-Eraso/Documents/simulating distributions and estimators/Estimator_Results")
options(stringsAsFactors = FALSE)

# ============================ RNG & REPRODUCIBILIDAD =====================
## Usamos L'Ecuyer-CMRG para reproducibilidad en paralelo y CRN
RNGkind("L'Ecuyer-CMRG")
set.seed(12345)
invisible(runif(1))

## Generador de índices CRN por (familia, n): mismos draws para TODAS las configs
make_crn_indices <- function(families, sample_sizes, B_boot = 100L, num_samples = 50L) {
  crn <- new.env(parent = emptyenv())
  ctr <- 1L
  for (fam in families) {
    for (n in sample_sizes) {
      ## Fijamos sub-semilla estable por par (fam, n)
      s_backup <- if (exists(".Random.seed", inherits = FALSE)) .Random.seed else NULL
      set.seed(1e6 + ctr)
      
      ## Índices/sortids que luego tu pipeline puede reutilizar
      sim_idx <- sample.int(1e9, num_samples, replace = FALSE)
      
      assign(paste(fam, n, sep = "__"),
             list(sim_idx = sim_idx),
             envir = crn)
      
      ## Restaurar estado RNG global (si existía)
      if (!is.null(s_backup)) .Random.seed <- s_backup
      ctr <- ctr + 1L
    }
  }
  crn
}

## ============================ SCENARIO BUILDERS ============================
## Full grid de escenarios
build_scenarios_full <- function(
    rates  = c(0.00, 0.01, 0.02, 0.05, 0.10, 0.15, 0.20, 0.30),
    scales = c(1.5, 3, 4.5, 6, 9, 12, 15, 20, 30),
    types  = c("upper_tail", "lower_tail", "symmetric_t", "point_mass")
) {
  expand.grid(
    contamination_rate = rates,
    outlier_scale_mad  = scales,
    contamination_type = types,
    stringsAsFactors = FALSE
  )
}

## Light grid (proxy rápido)
build_scenarios_light <- function() {
  expand.grid(
    contamination_rate = c(0.00, 0.02, 0.20),   # clean, mild, extreme
    outlier_scale_mad  = c(3, 9, 20),           # small, med, huge
    contamination_type = c("upper_tail", "symmetric_t"),
    stringsAsFactors = FALSE
  )
}

## Cache para warm-start entre configuraciones vecinas (misma familia/seed)
.init_pop_cache <- new.env(parent = emptyenv())
get_warm_start <- function(fam, seed) {
  key <- paste(fam, seed, sep = "::")
  if (exists(key, envir = .init_pop_cache)) get(key, envir = .init_pop_cache) else NULL
}
set_warm_start <- function(fam, seed, population) {
  key <- paste(fam, seed, sep = "::")
  assign(key, population, envir = .init_pop_cache)
}

## Early stopping con umbral de mejora mínima (pensado p/~40 gens de tope).
## Sugerencia: check_every=2-3, patience=3, min_delta=0.005-0.01.
should_stop <- function(val_hist, patience = 3L, min_delta = 0.005) {
  L <- length(val_hist)
  if (L < patience + 1L) return(FALSE)
  best_prev   <- min(val_hist[1:(L - patience)])
  best_recent <- min(val_hist[(L - patience + 1L):L])
  improvement <- (best_prev - best_recent) / (abs(best_prev) + 1e-12)
  improvement < min_delta
}

## Normalización defensiva al simplex (para vectores de pesos)
.normalize_simplex <- function(w, eps = 1e-12) {
  w <- as.numeric(w)
  w[!is.finite(w)] <- eps
  w[w < eps] <- eps
  s <- sum(w)
  if (s <= eps) {
    w[] <- 1 / length(w)
  } else {
    w <- w / s
  }
  w
}

# ============================ HELPERS MINI-BATCH HP ======================
# Muestrea un subconjunto de filas (configs) con semilla. Opción de estratificar.
# Uso típico en Fase 1: pick_minibatch_configs(cfg_grid, frac=0.25, seed=13)
# O bien: pick_minibatch_configs(cfg_grid, k=64, seed=13, stratify_cols=c("pop_size","t_size"))
pick_minibatch_configs <- function(cfg_grid, frac = NULL, k = NULL, seed = 13, stratify_cols = NULL) {
  stopifnot(is.data.frame(cfg_grid), nrow(cfg_grid) >= 1)
  if (is.null(frac) && is.null(k)) stop("Indica 'frac' o 'k'.")
  set.seed(seed)
  
  # tamaño objetivo
  target <- if (!is.null(k)) max(1L, min(nrow(cfg_grid), as.integer(k))) else {
    max(1L, min(nrow(cfg_grid), as.integer(ceiling(nrow(cfg_grid) * frac))))
  }
  
  if (is.null(stratify_cols) || length(stratify_cols) == 0) {
    idx <- sample(seq_len(nrow(cfg_grid)), size = target, replace = FALSE)
    return(cfg_grid[idx, , drop = FALSE])
  }
  
  # Estratificado: repartimos cuotas por grupo de (stratify_cols)
  g <- interaction(cfg_grid[, stratify_cols], drop = TRUE, lex.order = TRUE)
  splits <- split(seq_len(nrow(cfg_grid)), g)
  # cuota por grupo (redondeo hacia arriba para no quedarnos cortos)
  q <- ceiling(target * sapply(splits, length) / nrow(cfg_grid))
  
  take <- integer(0)
  for (nm in names(splits)) {
    pool <- splits[[nm]]
    if (length(pool) == 0) next
    kk <- min(q[[nm]], length(pool))
    take <- c(take, sample(pool, kk))
  }
  # Si nos pasamos, recortamos; si faltan, completamos aleatorio
  if (length(take) > target) take <- sample(take, target)
  if (length(take) < target) {
    rest <- setdiff(seq_len(nrow(cfg_grid)), take)
    need <- target - length(take)
    take <- c(take, sample(rest, min(need, length(rest))))
  }
  cfg_grid[sort(unique(take)), , drop = FALSE]
}




# ============================ UTILIDADES I/O =============================

RUN_TS <- function() format(Sys.time(), "%Y%m%d_%H%M%S")

mkdirp <- function(p) {
  if (!dir.exists(p)) dir.create(p, recursive = TRUE, showWarnings = FALSE)
  invisible(normalizePath(p, winslash = "/", mustWork = FALSE))
}

# Logger simple con timestamp
catf <- function(fmt, ...) {
  msg <- sprintf(fmt, ...)
  cat(sprintf("[%s] %s\n", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), msg))
}

# Escribe líneas al archivo creando carpeta; devuelve ruta
safe_write_lines <- function(lines, path) {
  mkdirp(dirname(path))
  con <- file(path, open = "wt", encoding = "UTF-8")
  on.exit(close(con), add = TRUE)
  writeLines(lines, con = con, sep = "\n", useBytes = TRUE)
  invisible(path)
}

# Guardado robusto para RDS / CSV
safe_save_rds <- function(obj, path) {
  mkdirp(dirname(path))
  saveRDS(obj, file = path)
  invisible(path)
}

safe_write_csv <- function(df, path) {
  if (!is.data.frame(df) || !nrow(df)) return(invisible(NULL))
  mkdirp(dirname(path))
  if (requireNamespace("readr", quietly = TRUE)) {
    readr::write_csv(df, path)
  } else {
    utils::write.csv(df, path, row.names = FALSE)
  }
  invisible(path)
}

# Intenta obtener info de git (hash corto y rama) si estamos en repo
.git_info <- function() {
  tryCatch({
    hash <- suppressWarnings(system("git rev-parse --short HEAD", intern = TRUE))
    br   <- suppressWarnings(system("git rev-parse --abbrev-ref HEAD", intern = TRUE))
    if (length(hash) && length(br)) sprintf("%s (%s)", hash[1], br[1]) else NA_character_
  }, error = function(e) NA_character_)
}

# Escribe MANIFEST.txt + snapshot de sesión (SESSION.txt). Opción extra para “muestra” de datos.
write_manifest <- function(dir_out, meta, extra = NULL, write_session = TRUE) {
  mkdirp(dir_out)
  fmt_vec <- function(x) {
    if (is.null(x)) return("NULL")
    if (is.list(x))  return(paste(capture.output(str(x, give.attr = FALSE)), collapse = " "))
    if (length(x) > 1) paste0("[", paste(x, collapse = ", "), "]") else as.character(x)
  }
  
  scenario_mode_line <- meta$scenario_mode %||% "full"
  git_line <- .git_info()
  
  lines <- c(
    sprintf("# RUN_ID: %s", meta$run_id %||% RUN_TS()),
    sprintf("timestamp: %s", as.character(Sys.time())),
    sprintf("git: %s", ifelse(is.na(git_line), "NA", git_line)),
    sprintf("platform: %s | R: %s | locale: %s",
            paste(R.version$platform, R.version$arch, sep = "/"),
            getRversion(), Sys.getlocale()),
    "",
    "## CONFIG",
    sprintf("families: %s", fmt_vec(meta$families)),
    sprintf("k_folds: %s", meta$k_folds %||% NA),
    sprintf("objective: %s", meta$objective %||% NA),
    sprintf("seeds: %s", fmt_vec(meta$seeds %||% meta$seed)),
    sprintf("pop_sizes: %s", fmt_vec(meta$pop_sizes)),
    sprintf("generations_per_fold: %s", meta$generations_per_fold %||% NA),
    sprintf("final_retrain: %s", meta$final_retrain %||% NA),
    sprintf("bootstrap_B: %s", meta$bootstrap_B %||% NA),
    sprintf("lambda_instab (default): %s", meta$lambda_instab_default %||% NA),
    sprintf("scenario_mode: %s", scenario_mode_line),
    sprintf("minibatch_frac: %s", meta$minibatch_frac %||% NA),
    sprintf("minibatch_min: %s", meta$minibatch_min %||% NA)
  )
  
  if (!is.null(extra)) {
    lines <- c(lines, "", "## EXTRA (preview)", capture.output(print(utils::head(extra, 10))))
  }
  
  mf_path <- file.path(dir_out, "MANIFEST.txt")
  safe_write_lines(lines, mf_path)
  catf("MANIFEST escrito en: %s", mf_path)
  
  if (isTRUE(write_session)) {
    sess_path <- file.path(dir_out, "SESSION.txt")
    sink(sess_path)
    on.exit({ if (sink.number() > 0) sink() }, add = TRUE)
    cat("# sessionInfo()\n\n"); print(utils::sessionInfo()); cat("\n")
    pkgs <- tryCatch(installed.packages()[, c("Package","Version")], error = function(e) NULL)
    if (!is.null(pkgs)) {
      cat("# installed.packages() snapshot (Package / Version)\n\n")
      print(utils::head(as.data.frame(pkgs), 50))
    }
    sink()
    catf("SESSION escrito en: %s", sess_path)
  }
  
  invisible(mf_path)
}


# ============================ PROGRESS HELPERS ============================
.progress <- new.env(parent = emptyenv())

progress_init <- function(total_steps) {
  .progress$done  <- 0L
  .progress$total <- max(1L, as.integer(total_steps))
  .progress$pb    <- utils::txtProgressBar(min = 0, max = 100, style = 3)
  utils::setTxtProgressBar(.progress$pb, 0)
}

progress_step <- function(label = NULL, inc = 1L) {
  .progress$done <- min(.progress$done + as.integer(inc), .progress$total)
  pct <- round(100 * .progress$done / .progress$total)
  if (!is.null(.progress$pb)) utils::setTxtProgressBar(.progress$pb, pct)
  if (!is.null(label)) catf("Progreso %3d%% | %s", pct, label)
}

progress_finalize <- function() {
  if (!is.null(.progress$pb)) {
    utils::setTxtProgressBar(.progress$pb, 100)
    close(.progress$pb); .progress$pb <- NULL
  }
  catf("Progreso 100%% | DONE")
}

# ============================ RNG & FAMILIAS =============================

rexwald <- function(n, mu = 1, lambda = 1, rate = 1) {
  stopifnot(length(n) == 1L, is.finite(n), n >= 0,
            is.finite(mu), is.finite(lambda), is.finite(rate))
  if (n == 0) return(numeric(0))
  if (lambda <= 0 || rate <= 0) stop("rexwald: 'lambda' y 'rate' deben ser > 0")
  T0 <- rexp(n, rate = rate)
  W  <- statmod::rinvgauss(n, mean = mu, shape = lambda)
  T0 + W
}

rexgaussian <- function(n, mu = 0, sigma = 1, tau = 1) {
  stopifnot(length(n) == 1L, is.finite(n), n >= 0,
            is.finite(mu), is.finite(sigma), is.finite(tau))
  if (n == 0) return(numeric(0))
  if (sigma <= 0 || tau <= 0) stop("rexgaussian: 'sigma' y 'tau' deben ser > 0")
  rnorm(n, mean = mu, sd = sigma) + rexp(n, rate = 1 / tau)
}

# Generador robusto con manejo defensivo de parámetros y mensajes claros
generate_population <- function(distribution, n, params = list()) {
  if (!is.character(distribution) || length(distribution) != 1L)
    stop("generate_population: 'distribution' debe ser un string único.")
  if (!is.numeric(n) || length(n) != 1L || n < 0)
    stop("generate_population: 'n' debe ser un número no-negativo de longitud 1.")
  if (n == 0) return(numeric(0))
  
  distribution <- tolower(trimws(distribution))
  params <- as.list(params)
  getp <- function(name, default = NULL, required = FALSE) {
    if (!is.null(params[[name]])) return(params[[name]])
    if (required) stop(sprintf("generate_population(%s): falta parámetro '%s'.",
                               distribution, name))
    default
  }
  
  out <- switch(distribution,
                normal = {
                  mean <- getp("mean", 0); sd <- getp("sd", 1)
                  if (!is.finite(sd) || sd <= 0) stop("normal: 'sd' debe ser > 0 y finito.")
                  rnorm(n, mean = mean, sd = sd)
                },
                lognormal = {
                  meanlog <- getp("meanlog", 0); sdlog <- getp("sdlog", 1)
                  if (!is.finite(sdlog) || sdlog <= 0) stop("lognormal: 'sdlog' debe ser > 0 y finito.")
                  rlnorm(n, meanlog = meanlog, sdlog = sdlog)
                },
                weibull = {
                  shape <- getp("shape", required = TRUE); scale <- getp("scale", required = TRUE)
                  if (!is.finite(shape) || shape <= 0) stop("weibull: 'shape' debe ser > 0 y finito.")
                  if (!is.finite(scale) || scale <= 0) stop("weibull: 'scale' debe ser > 0 y finito.")
                  rweibull(n, shape = shape, scale = scale)
                },
                invgauss = {
                  mean <- getp("mean", required = TRUE); shape <- getp("shape", required = TRUE)
                  if (!is.finite(mean)  || mean  <= 0) stop("invgauss: 'mean' debe ser > 0 y finito.")
                  if (!is.finite(shape) || shape <= 0) stop("invgauss: 'shape' debe ser > 0 y finito.")
                  statmod::rinvgauss(n, mean = mean, shape = shape)
                },
                exgaussian = {
                  mu <- getp("mu", 0); sigma <- getp("sigma", 1); tau <- getp("tau", 1)
                  if (!is.finite(sigma) || sigma <= 0) stop("exgaussian: 'sigma' debe ser > 0 y finito.")
                  if (!is.finite(tau)   || tau   <= 0) stop("exgaussian: 'tau' debe ser > 0 y finito.")
                  rexgaussian(n, mu = mu, sigma = sigma, tau = tau)
                },
                exwald = {
                  mu <- getp("mu", 1); lambda <- getp("lambda", 1); rate <- getp("rate", 1)
                  if (!is.finite(lambda) || lambda <= 0) stop("exwald: 'lambda' debe ser > 0 y finito.")
                  if (!is.finite(rate)   || rate   <= 0) stop("exwald: 'rate' debe ser > 0 y finito.")
                  rexwald(n, mu = mu, lambda = lambda, rate = rate)
                },
                stop(sprintf("Unsupported distribution: %s", distribution))
  )
  
  # Guard final: elimina no finitos si algún borde numérico se cuela
  out <- out[is.finite(out)]
  if (!length(out)) stop("generate_population: no se pudo generar muestra finita.")
  out
}


# ============================ PARAMETER GRIDS ============================

# Defaults (compactos y legibles)
.param_grids_default <- list(
  normal     = expand.grid(mean = c(1, 5),
                           sd   = c(1, sqrt(2), 2, 3),
                           KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE),
  lognormal  = expand.grid(meanlog = c(0.5, 1),
                           sdlog   = c(0.25, 0.5, 1),
                           KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE),
  weibull    = expand.grid(shape = c(0.5, 1, 2, 3),
                           scale = c(0.5, 1, 2),
                           KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE),
  invgauss   = expand.grid(mean  = c(0.5, 1, 2),
                           shape = c(0.5, 1, 2),
                           KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE),
  exgaussian = expand.grid(mu    = c(0, 1, 2),
                           sigma = c(0.5, 1, 1.5),
                           tau   = c(0.25, 0.5, 1),
                           KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE),
  exwald     = expand.grid(mu     = c(1, 1.5, 2),
                           lambda = c(0.5, 1, 2),
                           rate   = c(0.25, 0.5, 1),
                           KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE)
)

# Validador mínimo por familia (por si sobrescribes con algo raro)
.validate_grid <- function(name, g) {
  if (!is.data.frame(g) || !nrow(g)) stop(sprintf("Grid vacío/ inválido para '%s'.", name))
  g[] <- lapply(g, function(col) { col[!is.finite(col)] <- NA_real_; col })
  g <- stats::na.omit(g)
  if (name %in% c("weibull")) {
    g <- subset(g, shape > 0 & scale > 0)
  } else if (name %in% c("invgauss")) {
    g <- subset(g, mean > 0 & shape > 0)
  } else if (name %in% c("exgaussian")) {
    g <- subset(g, sigma > 0 & tau > 0)
  } else if (name %in% c("exwald")) {
    g <- subset(g, lambda > 0 & rate > 0)
  } else if (name %in% c("normal")) {
    g <- subset(g, sd > 0)
  } else if (name %in% c("lognormal")) {
    g <- subset(g, sdlog > 0)
  }
  if (!nrow(g)) stop(sprintf("Tras validación el grid de '%s' quedó vacío.", name))
  unique(g)
}

# Constructor flexible: puedes pasar overrides como lista: list(normal=..., weibull=...)
build_param_grids <- function(overrides = NULL, families = names(.param_grids_default)) {
  families <- intersect(tolower(families), names(.param_grids_default))
  if (!length(families)) stop("build_param_grids: 'families' no coincide con defaults.")
  res <- list()
  for (nm in families) {
    g <- if (!is.null(overrides) && !is.null(overrides[[nm]])) overrides[[nm]] else .param_grids_default[[nm]]
    res[[nm]] <- .validate_grid(nm, g)
  }
  res
}

# Para compatibilidad con tu código actual:
param_grids <- build_param_grids()
# ------------------------------------------------------------------------


# ======================== SET DE ESTIMADORES ============================

# Helper: cuantiles robustos (evita warnings si hay muchos NA)
.qs3 <- function(x) {
  stats::quantile(x, probs = c(0.25, 0.50, 0.75), names = FALSE, type = 8, na.rm = TRUE)
}

harmonic_mean_safe <- function(x) {
  x <- as.numeric(x); if (!length(x)) return(NA_real_)
  xp <- x[is.finite(x) & x > 0]
  if (!length(xp)) return(stats::median(x, na.rm = TRUE))
  length(xp) / sum(1 / xp)
}

geometric_mean_safe <- function(x) {
  x <- as.numeric(x); if (!length(x)) return(NA_real_)
  xp <- x[is.finite(x) & x > 0]
  if (!length(xp)) return(stats::median(x, na.rm = TRUE))
  exp(base::mean(log(xp)))
}

mode_hsm_safe <- function(x) {
  x <- as.numeric(x)
  out <- tryCatch(modeest::hsm(x), error = function(e) NA_real_)
  if (!is.finite(out)) stats::median(x, na.rm = TRUE) else out
}

mode_parzen_safe <- function(x) {
  x <- as.numeric(x)
  out <- tryCatch(as.numeric(modeest::mlv(x, method = "parzen")),
                  error = function(e) NA_real_)
  if (!is.finite(out)) stats::median(x, na.rm = TRUE) else out
}

trimean_safe <- function(x) {
  x <- as.numeric(x); q <- .qs3(x); (q[1] + 2*q[2] + q[3]) / 4
}

huber_mean_safe <- function(x) {
  x <- as.numeric(x)
  out <- tryCatch({
    fit <- MASS::rlm(x ~ 1, psi = MASS::psi.huber, scale.est = "MAD",
                     maxit = 50, na.action = na.omit)
    as.numeric(coef(fit)[1])
  }, error = function(e) NA_real_)
  if (!is.finite(out)) stats::median(x, na.rm = TRUE) else out
}

biweight_mean_safe <- function(x) {
  x <- as.numeric(x)
  out <- tryCatch({
    fit <- MASS::rlm(x ~ 1, psi = MASS::psi.bisquare, scale.est = "MAD",
                     maxit = 50, na.action = na.omit)
    as.numeric(coef(fit)[1])
  }, error = function(e) NA_real_)
  if (!is.finite(out)) stats::median(x, na.rm = TRUE) else out
}

# ---------- Registry de estimadores (nombres + funciones) ---------------
ESTIMATOR_REGISTRY <- list(
  mean        = function(x) base::mean(x, na.rm = TRUE),
  median      = function(x) stats::median(x, na.rm = TRUE),
  trimmed20   = function(x) base::mean(x, trim = 0.20, na.rm = TRUE),
  harmonic    = harmonic_mean_safe,
  geometric   = geometric_mean_safe,
  mode_hsm    = mode_hsm_safe,
  mode_parzen = mode_parzen_safe,
  trimean     = trimean_safe,
  huber       = huber_mean_safe,
  biweight    = biweight_mean_safe
)

ESTIMATOR_NAMES <- names(ESTIMATOR_REGISTRY)
N_EST <- length(ESTIMATOR_NAMES)

# Acepta pesos en cualquier escala y los normaliza (usa .normalize_simplex global)
custom_estimator <- function(sample, weights) {
  stopifnot(length(weights) == N_EST)
  w <- .normalize_simplex(as.numeric(weights))
  x <- as.numeric(sample)
  comps <- vapply(ESTIMATOR_REGISTRY, function(f) {
    out <- tryCatch(f(x), error = function(e) NA_real_)
    if (!is.finite(out)) stats::median(x, na.rm = TRUE) else out
  }, numeric(1))
  sum(w * comps)
}

weights_to_formula <- function(weights) {
  stopifnot(length(weights) == N_EST)
  w <- round(.normalize_simplex(as.numeric(weights)), 3)
  paste0(paste0(w, "*", ESTIMATOR_NAMES), collapse = " + ")
}



































# ======= POBLACIÓN, CROSSOVER y MUTACIÓN =================================

init_population <- function(size, n_estimators, alpha = 1, warm_start = NULL, jitter = 0.15) {
  stopifnot(size >= 1L, n_estimators >= 1L, is.finite(alpha), alpha > 0)
  # Base Dirichlet
  pop <- matrix(gtools::rdirichlet(size, rep(alpha, n_estimators)),
                nrow = size, byrow = TRUE)
  
  # Warm-start (opcional): injerta algunos individuos y añade "jitter" dirichlet
  if (!is.null(warm_start)) {
    ws <- as.matrix(warm_start)
    if (ncol(ws) != n_estimators) {
      if (ncol(ws) > n_estimators) ws <- ws[, seq_len(n_estimators), drop = FALSE]
      if (ncol(ws) < n_estimators) {
        add <- matrix(0, nrow = nrow(ws), ncol = n_estimators - ncol(ws))
        ws <- cbind(ws, add)
      }
    }
    ws <- t(apply(ws, 1, .normalize_simplex))
    k <- min(nrow(ws), size)
    if (k > 0) {
      # jitter suave para diversidad sin romper el simplex
      eps <- matrix(gtools::rdirichlet(k, rep(alpha + jitter, n_estimators)),
                    nrow = k, byrow = TRUE)
      pop[seq_len(k), ] <- t(apply((ws[seq_len(k), , drop = FALSE] + eps) / 2, 1, .normalize_simplex))
    }
  }
  # Normaliza por seguridad
  pop <- t(apply(pop, 1, .normalize_simplex))
  pop
}

crossover <- function(parent1, parent2) {
  stopifnot(length(parent1) == length(parent2))
  a <- stats::runif(1)  # mezcla aleatoria
  child <- a * as.numeric(parent1) + (1 - a) * as.numeric(parent2)
  .normalize_simplex(child)
}

mutate_weights <- function(weights, mutation_rate = 0.10, alpha_mut = 1) {
  w <- .normalize_simplex(as.numeric(weights))
  mutation_rate <- min(max(mutation_rate, 0), 1)  # clip a [0,1]
  if (stats::runif(1) < mutation_rate) {
    alpha_mut <- max(alpha_mut, 1e-6)
    perturb <- as.numeric(gtools::rdirichlet(1, rep(alpha_mut, length(w))))
    w <- (w + perturb) / 2
  }
  .normalize_simplex(w)
}

# ====================== CONTAMINACIÓN REALISTA ===========================

inject_outliers_realistic <- function(sample,
                                      contamination_rate = 0.05,
                                      outlier_scale_mad = 12,
                                      type = c("upper_tail", "symmetric_t", "lower_tail", "point_mass"),
                                      df_t = 3) {
  type <- match.arg(type)
  n <- length(sample)
  if (!n) return(sample)
  k <- ceiling(n * contamination_rate)
  if (k <= 0) return(sample)
  
  med  <- stats::median(sample)
  madv <- stats::mad(sample, constant = 1, na.rm = TRUE)
  if (!is.finite(madv) || madv <= 0) {
    # fallback: sd robustecida (si sd=0, usa 1 para evitar punto fijo)
    sdv <- stats::sd(sample)
    madv <- if (is.finite(sdv) && sdv > 0) sdv else 1
  }
  
  idx <- base::sample.int(n, size = k, replace = FALSE)
  
  if (type == "upper_tail") {
    bump <- abs(stats::rnorm(k))
    outlier_values <- med + outlier_scale_mad * madv * bump
  } else if (type == "symmetric_t") {
    bump <- stats::rt(k, df = df_t)
    outlier_values <- med + outlier_scale_mad * madv * bump
  } else if (type == "lower_tail") {
    bump <- abs(stats::rnorm(k))
    outlier_values <- med - outlier_scale_mad * madv * bump
  } else { # point_mass
    outlier_values <- rep(med + outlier_scale_mad * madv, k)
  }
  
  sample[idx] <- outlier_values
  sample
}

# ============================ ESCENARIOS & DATA ==========================

## Dispatcher light/full
build_scenarios <- function(mode = c("full","light")) {
  mode <- match.arg(mode)
  if (mode == "full") build_scenarios_full() else build_scenarios_light()
}

compute_components_vector <- function(x) {
  # defensivo: quita no finitos si aparecieran
  x <- as.numeric(x); x <- x[is.finite(x)]
  if (!length(x)) return(rep(NA_real_, N_EST))
  # Usa el registry para mantener consistencia nombres <-> componentes
  comps <- vapply(ESTIMATOR_REGISTRY, function(f) {
    out <- tryCatch(f(x), error = function(e) NA_real_)
    if (!is.finite(out)) stats::median(x, na.rm = TRUE) else out
  }, numeric(1))
  as.numeric(comps)
}

# --- Helper: evaluar expr con semilla local sin afectar RNG global -------
.seed_scope <- function(seed, expr) {
  s_backup_exists <- exists(".Random.seed", inherits = FALSE)
  if (s_backup_exists) s_backup <- .Random.seed
  on.exit({
    if (s_backup_exists) .Random.seed <<- s_backup
  }, add = TRUE)
  set.seed(seed)
  force(expr)
}

# --- PREP con CRN: usa sim-seeds por (familia, n) para muestrear reproducible
# 'crn_env' viene de make_crn_indices(); key = paste(family, n, sep="__")
prep_scenarios <- function(dist_name, dist_param_grid,
                           sample_sizes = c(50, 100, 300, 500, 1000, 2000),
                           num_samples = 80,
                           scenario_mode = c("full","light"),
                           seed = 123,
                           crn_env = NULL,
                           fam_key = NULL) {
  set.seed(seed)
  scenario_mode <- match.arg(scenario_mode)
  scenarios <- build_scenarios(scenario_mode)
  
  # 1) Población combinada grande para aproximar el "true mean"
  combined_population <- unlist(lapply(seq_len(nrow(dist_param_grid)), function(i) {
    param <- as.list(dist_param_grid[i, , drop = FALSE])
    tryCatch(generate_population(dist_name, 1e5, param), error = function(e) NULL)
  }))
  combined_population <- combined_population[is.finite(combined_population)]
  if (length(combined_population) == 0) stop("Failed to generate combined population.")
  true_mean <- base::mean(combined_population)
  
  # 2) Para cada escenario y cada n: num_samples replicaciones con CRN si hay
  prepped <- lapply(seq_len(nrow(scenarios)), function(i) {
    sc <- scenarios[i, ]
    sc$contamination_type <- as.character(sc$contamination_type)
    
    components_by_size <- lapply(sample_sizes, function(n) {
      crn_key <- if (!is.null(fam_key)) paste(fam_key, n, sep = "__") else NULL
      sim_seeds <- NULL
      if (!is.null(crn_env) && !is.null(crn_key) && exists(crn_key, envir = crn_env)) {
        obj <- get(crn_key, envir = crn_env)
        sim_seeds <- obj$sim_idx
        if (length(sim_seeds) < num_samples) {
          sim_seeds <- rep(sim_seeds, length.out = num_samples) # reciclaje determinístico
        } else {
          sim_seeds <- sim_seeds[seq_len(num_samples)]
        }
      }
      
      comps_mat <- matrix(NA_real_, nrow = num_samples, ncol = N_EST)
      for (r in seq_len(num_samples)) {
        # Muestra base
        if (!is.null(sim_seeds)) {
          replace_flag <- length(combined_population) < n
          s <- .seed_scope(sim_seeds[r],
                           base::sample(combined_population, n, replace = replace_flag))
        } else {
          replace_flag <- length(combined_population) < n
          s <- base::sample(combined_population, n, replace = replace_flag)
        }
        
        # Contaminación si aplica
        if (isTRUE(sc$contamination_rate > 0)) {
          s <- inject_outliers_realistic(
            s,
            contamination_rate = sc$contamination_rate,
            outlier_scale_mad  = sc$outlier_scale_mad,
            type               = sc$contamination_type
          )
        }
        comps_mat[r, ] <- compute_components_vector(s)
      }
      colnames(comps_mat) <- ESTIMATOR_NAMES
      comps_mat
    })
    
    names(components_by_size) <- as.character(sample_sizes)
    
    S_i <- list(
      components_by_size = components_by_size,
      true_mean = true_mean,
      scenario  = sc
    )
    attr(S_i, "scenario_mode") <- scenario_mode
    S_i
  })
  
  attr(prepped, "sample_sizes")  <- sample_sizes
  attr(prepped, "scenario_mode") <- scenario_mode
  prepped
}


# =============================== FITNESS =================================

# --- Huber loss (robusto a outliers) -------------------------------------
huber_loss <- function(r, delta = 1.0) {
  r <- as.numeric(r)
  a <- base::abs(r)
  ifelse(a <= delta, 0.5 * r^2, delta * (a - 0.5 * delta))
}

# --- Ponderación por dificultad del escenario ----------------------------
# Escala con tasa de contaminación y severidad; ligero boost a simetría t.
scenario_weight <- function(sc_row) {
  cr  <- sc_row$contamination_rate
  osm <- sc_row$outlier_scale_mad
  typ <- as.character(sc_row$contamination_type)
  base_w  <- 1 + 2 * cr + 0.03 * osm
  type_adj <- switch(typ,
                     "upper_tail"   = 1.05,
                     "lower_tail"   = 1.05,
                     "symmetric_t"  = 1.10,
                     "point_mass"   = 1.00,
                     1.00
  )
  base_w * type_adj
}

# --- Bootstrap q95 con control de RNG y atajos en casos degenerados ------
q95_boot <- function(x, B = 300L, rng_seed = NULL, boot_indices = NULL) {
  x <- as.numeric(x); x <- x[is.finite(x)]
  n <- length(x)
  if (n == 0L) return(NA_real_)
  if (n < 5L)  return(as.numeric(stats::quantile(x, 0.95, names = FALSE, type = 8)))
  if (all(x == x[1])) return(x[1])
  
  s_bkp_exists <- exists(".Random.seed", inherits = FALSE)
  if (s_bkp_exists) s_bkp <- .Random.seed
  if (!is.null(rng_seed)) {
    set.seed(rng_seed)
  } else if (!s_bkp_exists) {
    stats::runif(1)  # garantiza .Random.seed
  }
  
  if (!is.null(boot_indices)) {
    B_eff <- base::min(B, length(boot_indices))
    qs <- vapply(seq_len(B_eff), function(b) {
      xb <- x[ boot_indices[[b]] ]
      as.numeric(stats::quantile(xb, 0.95, names = FALSE, type = 8))
    }, numeric(1))
  } else {
    qs <- replicate(B, {
      xb <- base::sample(x, replace = TRUE)
      as.numeric(stats::quantile(xb, 0.95, names = FALSE, type = 8))
    })
  }
  
  if (s_bkp_exists) .Random.seed <<- s_bkp
  stats::median(qs)
}

# --- Fitness universal: combina objetivo + penalizaciones -----------------
fitness_universal <- function(w, prepped,
                              objective = c("mean","q95","max","mixed"),
                              idx = NULL,
                              use_boot = TRUE, B = 300,
                              # penalizaciones / mixing
                              lambda_instab = 0.0,
                              lambda_entropy = 0.015,
                              max_w_dominance = 0.80,
                              lambda_dominance = 0.05,
                              mix_w_q95 = 0.7,
                              mix_w_max = 0.3,
                              lambda_bias = 0.05,
                              # knobs de robustez
                              huber_delta = 1.0,
                              q95_seed = NULL,
                              q95_boot_indices = NULL) {
  w <- .normalize_simplex(as.numeric(w))
  objective <- match.arg(objective)
  
  # Subconjunto de escenarios
  Slist <- if (is.null(idx)) prepped else prepped[idx]
  if (length(Slist) == 0L) return(Inf)
  
  # Auto–ajuste de B si es light y B no fue fijado explícitamente
  if (!is.null(attr(prepped, "scenario_mode")) &&
      identical(attr(prepped, "scenario_mode"), "light") &&
      missing(B)) {
    B <- 60L
  }
  
  # --- Pérdidas por escenario (Huber) ------------------------------------
  losses_by_scen <- vapply(Slist, function(S) {
    ls_per_size <- vapply(S$components_by_size, function(C) {
      # C: (num_samples x N_EST)
      est <- as.vector(C %*% w)
      r   <- est - S$true_mean
      base::mean(huber_loss(r, delta = huber_delta), na.rm = TRUE)
    }, numeric(1))
    base::mean(ls_per_size) * scenario_weight(S$scenario)
  }, numeric(1))
  
  # Filtra no finitos; si todo es no-finito, fitness = Inf
  finite_mask <- is.finite(losses_by_scen)
  if (!any(finite_mask)) return(Inf)
  if (!all(finite_mask)) losses_by_scen <- losses_by_scen[finite_mask]
  
  # --- Sesgo medio por escenario (para penalización de bias) -------------
  bias_by_scen <- vapply(Slist[finite_mask], function(S) {
    base::mean(vapply(S$components_by_size, function(C) {
      est <- as.vector(C %*% w)
      base::mean(est, na.rm = TRUE) - S$true_mean
    }, numeric(1)))
  }, numeric(1))
  mean_abs_bias <- base::mean(base::abs(bias_by_scen), na.rm = TRUE)
  
  # --- Métrica base del objetivo -----------------------------------------
  q95_val  <- if (isTRUE(use_boot)) {
    q95_boot(losses_by_scen, B = B, rng_seed = q95_seed, boot_indices = q95_boot_indices)
  } else {
    as.numeric(stats::quantile(losses_by_scen, 0.95, names = FALSE, type = 8))
  }
  max_val  <- base::max(losses_by_scen)
  mean_val <- base::mean(losses_by_scen)
  
  base_obj <- switch(objective,
                     mean  = mean_val,
                     max   = max_val,
                     q95   = q95_val,
                     mixed = mix_w_q95 * q95_val + mix_w_max * max_val
  )
  
  # --- Penalizaciones -----------------------------------------------------
  penalty_instab <- lambda_instab * stats::sd(losses_by_scen, na.rm = TRUE)
  
  eps <- 1e-12
  entropy <- -sum(w * base::log(w + eps))
  entropy_norm <- entropy / base::log(length(w))
  pen_entropy <- lambda_entropy * (1 - entropy_norm)
  
  dom_excess <- base::max(0, base::max(w) - max_w_dominance)
  pen_dominance <- lambda_dominance * dom_excess
  
  pen_bias <- lambda_bias * mean_abs_bias
  
  base_obj + penalty_instab + pen_entropy + pen_dominance + pen_bias
}



# ======== BALANCED MINIBATCH HELPERS =====================================

# Firma simple por escenario para estratificar el muestreo
.scenario_sig <- function(S) {
  sc <- S$scenario
  paste(sc$contamination_type,
        sprintf("r=%.3f", sc$contamination_rate),
        sprintf("s=%.2f", sc$outlier_scale_mad),
        sep = "|")
}

# Muestra estratificada de índices de escenarios (balance aproximado por firma)
# - prepped: lista de escenarios preprocesados
# - pool_idx: vector de índices elegibles dentro de prepped
# - k: cuántos índices quieres
# - seed: semilla local para reproducibilidad SIN tocar el RNG global
balanced_sample_idx <- function(prepped, pool_idx, k, seed) {
  .seed_scope(seed, {
    pool_idx <- unique(as.integer(pool_idx))
    k <- as.integer(k)
    if (length(pool_idx) == 0L || k <= 0L) return(integer(0))
    if (k >= length(pool_idx)) return(pool_idx)
    
    # firmas por índice del pool
    sigs <- vapply(prepped[pool_idx], .scenario_sig, FUN.VALUE = character(1))
    by_sig <- split(pool_idx, sigs)
    
    # mezclar aleatoriamente el orden de buckets para evitar sesgos
    bucket_names <- sample(names(by_sig))
    
    take <- integer(0)
    # Ronda por ronda (round-robin) tomando 1 de cada bucket mezclado
    while (length(take) < k && length(by_sig) > 0) {
      for (nm in bucket_names) {
        b <- by_sig[[nm]]
        if (length(b) == 0L) next
        j <- base::sample(b, 1L)
        take <- c(take, j)
        # quitar el escogido del bucket
        by_sig[[nm]] <- setdiff(b, j)
        if (length(take) >= k) break
      }
      # eliminar buckets vacíos y re-mezclar el orden para la siguiente ronda
      by_sig <- Filter(length, by_sig)
      if (length(by_sig) == 0L) break
      bucket_names <- sample(names(by_sig))
    }
    unique(head(take, k))
  })
}


# ======================== SELECCIÓN / PARTICIONES ========================

# Selección por torneo (devuelve índices de ganadores para formar el "mating pool")
tournament_select <- function(scores, pop_size, t_size = 2L, replace = TRUE) {
  stopifnot(is.numeric(scores), length(scores) >= 2L, pop_size >= 2L, t_size >= 2L)
  n <- length(scores)
  t_size  <- min(t_size, n)             # seguridad si t_size > n
  n_pairs <- max(1L, pop_size %/% 2L)   # tamaño del mating pool
  winners <- integer(n_pairs)
  
  for (i in seq_len(n_pairs)) {
    cand <- base::sample.int(n, size = t_size, replace = FALSE)
    # rompe empates de manera estable (mínimo índice si hay empate)
    local_best <- cand[which.min(scores[cand])]
    winners[i] <- local_best
  }
  
  if (!replace) winners <- unique(winners)
  if (!replace && length(winners) < n_pairs) {
    ord  <- base::order(scores)         # completa con los mejores restantes
    need <- n_pairs - length(winners)
    winners <- c(winners, setdiff(ord, winners)[seq_len(need)])
  }
  winners
}

# K-folds estratificados por tamaño (balanceados en cantidad)
make_folds <- function(n, k, seed = NULL) {
  stopifnot(k >= 2L, n >= k)
  if (!is.null(seed)) {
    s_bkp <- if (exists(".Random.seed", inherits = FALSE)) .Random.seed else NULL
    on.exit({
      if (!is.null(s_bkp)) .Random.seed <<- s_bkp
      else rm(".Random.seed", inherits = FALSE)
    }, add = TRUE)
    set.seed(seed)
  }
  ids <- base::sample(seq_len(n))
  # Partición balanceada (diferencia de tamaños <= 1)
  split(ids, rep(seq_len(k), length.out = n))
}

# ================ WARM-STARTS DINÁMICOS (según N_EST) ====================
build_warm_starts <- function() {
  I   <- diag(N_EST)
  avg <- matrix(rep(1 / N_EST, N_EST), nrow = 1)
  
  z <- function(names) {
    v <- numeric(N_EST)
    present <- ESTIMATOR_NAMES %in% names
    k <- sum(present)
    if (k > 0) v[present] <- 1 / k
    v
  }
  
  combs <- rbind(
    z(c("mean","median")),
    z(c("median","trimmed20")),
    z(c("median","trimean","biweight")),
    z(c("huber","biweight")),
    z(c("geometric","harmonic"))
  )
  
  W <- unique(rbind(I, avg, combs))
  W <- t(apply(W, 1, .normalize_simplex))
  rs <- rowSums(W)
  if (any(rs == 0)) {
    W[rs == 0, ] <- matrix(rep(1 / N_EST, N_EST), nrow = sum(rs == 0), byrow = TRUE)
  }
  unique(W)
}


# =========================== MÉTRICAS / RESUMEN ==========================
summarize_scenario <- function(S, weights, distribution, sample_size,
                               q95_B = 300L, q95_seed = NULL, q95_boot_indices = NULL) {
  true_mu <- S$true_mean
  C <- S$components_by_size[[as.character(sample_size)]]
  
  # Si no hay datos para este tamaño, devuelve filas con NA (estructura consistente)
  if (is.null(C) || !is.matrix(C) || ncol(C) != N_EST) {
    base_row <- tibble::tibble(
      distribution = distribution,
      sample_size = as.integer(sample_size),
      contamination_rate = S$scenario$contamination_rate,
      outlier_scale_mad  = S$scenario$outlier_scale_mad,
      contamination_type = S$scenario$contamination_type,
      true_mean = true_mu,
      scenario_mode = { sm <- attr(S, "scenario_mode", exact = TRUE); if (is.null(sm)) "unknown" else sm }
    )
    na_metrics <- as.list(c(mse=NA_real_, mse_q95=NA_real_, mse_max=NA_real_,
                            bias=NA_real_, abs_bias=NA_real_,
                            variance=NA_real_, mad=NA_real_, iqr=NA_real_))
    return(dplyr::bind_rows(
      dplyr::bind_cols(base_row, estimator="robust",      na_metrics),
      dplyr::bind_cols(base_row, estimator="mean",        na_metrics),
      dplyr::bind_cols(base_row, estimator="median",      na_metrics),
      dplyr::bind_cols(base_row, estimator="trimmed20",   na_metrics),
      dplyr::bind_cols(base_row, estimator="harmonic",    na_metrics),
      dplyr::bind_cols(base_row, estimator="geometric",   na_metrics),
      dplyr::bind_cols(base_row, estimator="mode_hsm",    na_metrics),
      dplyr::bind_cols(base_row, estimator="mode_parzen", na_metrics),
      dplyr::bind_cols(base_row, estimator="trimean",     na_metrics),
      dplyr::bind_cols(base_row, estimator="huber",       na_metrics),
      dplyr::bind_cols(base_row, estimator="biweight",    na_metrics)
    ))
  }
  
  # Selector de columna robusto: si no existe, devuelve NA
  col_safe <- function(nm) {
    j <- match(nm, ESTIMATOR_NAMES)
    if (is.na(j)) rep(NA_real_, nrow(C)) else C[, j, drop = TRUE]
  }
  
  est_mean    <- col_safe("mean")
  est_median  <- col_safe("median")
  est_trim20  <- col_safe("trimmed20")
  est_harm    <- col_safe("harmonic")
  est_geom    <- col_safe("geometric")
  est_mode_h  <- col_safe("mode_hsm")
  est_mode_p  <- col_safe("mode_parzen")
  est_trimean <- col_safe("trimean")
  est_huber   <- col_safe("huber")
  est_biwt    <- col_safe("biweight")
  
  w_robust   <- .normalize_simplex(as.numeric(weights))
  est_robust <- as.vector(C %*% w_robust)
  
  agg <- function(z) {
    z <- as.numeric(z); z <- z[is.finite(z)]
    if (length(z) == 0L) {
      return(c(mse=NA, mse_q95=NA, mse_max=NA,
               bias=NA, abs_bias=NA,
               variance=NA, mad=NA, iqr=NA))
    }
    errs2 <- (z - true_mu)^2
    c(
      mse      = base::mean(errs2, na.rm = TRUE),
      mse_q95  = q95_boot(errs2, B = q95_B, rng_seed = q95_seed, boot_indices = q95_boot_indices),
      mse_max  = base::max(errs2, na.rm = TRUE),
      bias     = base::mean(z, na.rm = TRUE) - true_mu,
      abs_bias = base::abs(base::mean(z, na.rm = TRUE) - true_mu),
      variance = stats::var(z, na.rm = TRUE),
      mad      = stats::mad(z, constant = 1, na.rm = TRUE),
      iqr      = stats::IQR(z, na.rm = TRUE)
    )
  }
  
  m_mean    <- agg(est_mean)
  m_median  <- agg(est_median)
  m_trim20  <- agg(est_trim20)
  m_harm    <- agg(est_harm)
  m_geom    <- agg(est_geom)
  m_mode_h  <- agg(est_mode_h)
  m_mode_p  <- agg(est_mode_p)
  m_trimean <- agg(est_trimean)
  m_huber   <- agg(est_huber)
  m_biwt    <- agg(est_biwt)
  m_robust  <- agg(est_robust)
  
  base_row <- tibble::tibble(
    distribution = distribution,
    sample_size = as.integer(sample_size),
    contamination_rate = S$scenario$contamination_rate,
    outlier_scale_mad  = S$scenario$outlier_scale_mad,
    contamination_type = S$scenario$contamination_type,
    true_mean = true_mu,
    scenario_mode = { sm <- attr(S, "scenario_mode", exact = TRUE); if (is.null(sm)) "unknown" else sm }
  )
  
  dplyr::bind_rows(
    dplyr::bind_cols(base_row, estimator = "robust",      as.list(m_robust)),
    dplyr::bind_cols(base_row, estimator = "mean",        as.list(m_mean)),
    dplyr::bind_cols(base_row, estimator = "median",      as.list(m_median)),
    dplyr::bind_cols(base_row, estimator = "trimmed20",   as.list(m_trim20)),
    dplyr::bind_cols(base_row, estimator = "harmonic",    as.list(m_harm)),
    dplyr::bind_cols(base_row, estimator = "geometric",   as.list(m_geom)),
    dplyr::bind_cols(base_row, estimator = "mode_hsm",    as.list(m_mode_h)),
    dplyr::bind_cols(base_row, estimator = "mode_parzen", as.list(m_mode_p)),
    dplyr::bind_cols(base_row, estimator = "trimean",     as.list(m_trimean)),
    dplyr::bind_cols(base_row, estimator = "huber",       as.list(m_huber)),
    dplyr::bind_cols(base_row, estimator = "biweight",    as.list(m_biwt))
  )
}





# ---- Helpers para reducir repetición ------------------------------------

.ga_default_ctrl <- list(
  objective           = "q95",
  lambda_instab       = 0.15,
  bootstrap_B         = 200L,
  t_size              = 2L,
  elitism             = 2L,
  immigrant_rate      = 0.10,
  mutation_rate_init  = 0.18,
  init_alpha          = 1.0,
  alpha_mut           = 1.0,
  check_every         = 5L,
  patience            = 3L,
  min_delta           = 0.005,
  mix_w_q95           = 0.7,
  mix_w_max           = 0.3,
  lambda_entropy      = 0.015,
  max_w_dominance     = 0.80,
  lambda_dominance    = 0.05,
  lambda_bias         = 0.05,
  minibatch_frac      = NULL,   # fracción de escenarios de train (solo modo light)
  minibatch_min       = 12L     # mínimo de escenarios en minibatch
)

# Heurística para escoger "light" o "full" según el presupuesto total
.ga_pick_mode <- function(sample_sizes, num_samples, pop_size, generations) {
  n_scen_full <- nrow(build_scenarios_full())
  work_score  <- n_scen_full * length(sample_sizes) * num_samples * pop_size * generations
  if (work_score >= 5e7) "light" else "full"
}

# Cluster PSOCK con RNG reproducible
.ga_setup_cluster <- function(use_parallel, seed) {
  if (!use_parallel) return(NULL)
  n_cores <- suppressWarnings(max(1L, parallel::detectCores() - 1L))
  cl <- parallel::makeCluster(n_cores, type = "PSOCK")
  parallel::clusterSetRNGStream(cl, iseed = seed)
  parallel::clusterEvalQ(cl, { runif(1); NULL })
  cl
}

# Exporta objetos necesarios al cluster
.ga_export_cluster <- function(cl, env) {
  if (is.null(cl)) return(invisible(NULL))
  parallel::clusterExport(
    cl,
    varlist = c(
      # funciones de fitness y dependencias
      "fitness_universal","q95_boot","huber_loss","scenario_weight",".normalize_simplex",
      # datos/controles que .ga_eval_split usará dentro de parLapply
      "prepped","N_EST","ESTIMATOR_NAMES",".ga_eval_split","ctrl"
    ),
    envir = env
  )
  parallel::clusterEvalQ(cl, {
    suppressPackageStartupMessages({ library(dplyr); library(tibble); library(MASS) })
    NULL
  })
}

# Decaimiento suave de la tasa de mutación
.ga_decay_mut <- function(g, gmax, m0, mmin = 0.05) {
  g <- max(1L, as.integer(g)); gmax <- max(1L, as.integer(gmax))
  mmin + (m0 - mmin) * (log(gmax + 1) - log(g + 1)) / log(gmax + 1)
}

# Wrapper de evaluación que fija objetivo y penalizaciones desde ctrl
.ga_eval_split <- function(w, prepped, idx, ctrl, q95_seed) {
  fitness_universal(
    w, prepped, objective = ctrl$objective,
    idx = idx, use_boot = TRUE, B = ctrl$bootstrap_B,
    lambda_instab    = ctrl$lambda_instab,
    lambda_entropy   = ctrl$lambda_entropy,
    max_w_dominance  = ctrl$max_w_dominance,
    lambda_dominance = ctrl$lambda_dominance,
    mix_w_q95        = ctrl$mix_w_q95,
    mix_w_max        = ctrl$mix_w_max,
    lambda_bias      = ctrl$lambda_bias,
    q95_seed         = q95_seed
  )
}



# =========================== GA (single split) ===========================

evolve_universal_estimator_per_family <- function(dist_name,
                                                  dist_param_grid,
                                                  sample_sizes = c(300, 500, 1000, 2000, 5000),
                                                  num_samples = 80,
                                                  pop_size = 100,
                                                  generations = 50,
                                                  seed = 101,
                                                  objective = c("mean","q95","max","mixed"),
                                                  record_convergence = TRUE,
                                                  use_parallel = TRUE,
                                                  train_idx = NULL, val_idx = NULL,
                                                  lambda_instab = 0.15,
                                                  bootstrap_B = 200L,
                                                  t_size = 2L,
                                                  elitism = 2L,
                                                  immigrant_rate = 0.10,
                                                  mutation_rate_init = 0.18,
                                                  init_alpha = 1.0,
                                                  alpha_mut = 1.0,
                                                  check_every = 5L,
                                                  patience = 3L,
                                                  min_delta = 0.005,
                                                  warm_start_matrix = NULL,
                                                  return_val_best = TRUE,
                                                  mix_w_q95 = 0.7,
                                                  mix_w_max = 0.3,
                                                  lambda_entropy = 0.015,
                                                  max_w_dominance = 0.80,
                                                  lambda_dominance = 0.05,
                                                  lambda_bias = 0.05,
                                                  # ---- minibatch solo en LIGHT ----
                                                  minibatch_frac = NULL,
                                                  minibatch_min  = 12L,
                                                  # ---- CRN ----
                                                  crn_env = NULL,
                                                  fam_key = NULL,
                                                  # ---- MODO ESTRICTO: forzar light/full (sin heurístico) ----
                                                  force_scenario_mode = NULL) {
  stopifnot(pop_size >= 2L, generations >= 1L, length(sample_sizes) >= 1L)
  set.seed(seed)
  
  # ------ Unificar controles --------------------------------------------
  ctrl <- modifyList(.ga_default_ctrl, list(
    objective          = match.arg(objective),
    lambda_instab      = lambda_instab,
    bootstrap_B        = as.integer(bootstrap_B),
    t_size             = as.integer(t_size),
    elitism            = as.integer(elitism),
    immigrant_rate     = immigrant_rate,
    mutation_rate_init = mutation_rate_init,
    init_alpha         = init_alpha,
    alpha_mut          = alpha_mut,
    check_every        = as.integer(check_every),
    patience           = as.integer(patience),
    min_delta          = min_delta,
    mix_w_q95          = mix_w_q95,
    mix_w_max          = mix_w_max,
    lambda_entropy     = lambda_entropy,
    max_w_dominance    = max_w_dominance,
    lambda_dominance   = lambda_dominance,
    lambda_bias        = lambda_bias,
    minibatch_frac     = minibatch_frac,
    minibatch_min      = as.integer(minibatch_min)
  ))
  
  # ---- Preparar escenarios (MODO ESTRICTO: forzado si viene) ------------
  scenario_mode <- if (!is.null(force_scenario_mode)) {
    match.arg(force_scenario_mode, c("full","light"))
  } else {
    .ga_pick_mode(sample_sizes, num_samples, pop_size, generations)
  }
  prepped <- prep_scenarios(
    dist_name, dist_param_grid,
    sample_sizes  = sample_sizes,
    num_samples   = num_samples,
    scenario_mode = scenario_mode,
    seed          = seed,
    crn_env       = crn_env,
    fam_key       = if (is.null(fam_key)) dist_name else fam_key
  )
  prepped_mode <- attr(prepped, "scenario_mode")
  
  # ---- Partición train/val si no viene dada -----------------------------
  all_idx <- seq_along(prepped)
  if (is.null(val_idx) || is.null(train_idx)) {
    folds <- make_folds(length(all_idx), k = 3, seed = seed)
    val_idx   <- sort(unlist(folds[[3]]))
    train_idx <- sort(setdiff(all_idx, val_idx))
  } else {
    train_idx <- sort(unique(train_idx))
    val_idx   <- sort(unique(val_idx))
  }
  
  # ---- Warm-starts ------------------------------------------------------
  warm_cache <- get_warm_start(dist_name, seed)
  warm <- build_warm_starts()
  if (!is.null(warm_start_matrix)) warm <- unique(rbind(warm_start_matrix, warm))
  if (!is.null(warm_cache))        warm <- unique(rbind(warm_cache, warm))
  rest <- max(0L, pop_size - nrow(warm))
  ga_population <- if (rest > 0L) rbind(warm, init_population(rest, N_EST, alpha = ctrl$init_alpha)) else warm
  ga_population <- t(apply(ga_population, 1, .normalize_simplex))
  
  # ---- Paralelización ---------------------------------------------------
  cl <- .ga_setup_cluster(use_parallel, seed)
  on.exit({ if (!is.null(cl)) try(parallel::stopCluster(cl), silent = TRUE) }, add = TRUE)
  .ga_export_cluster(cl, environment())
  
  # ---- Tracking ---------------------------------------------------------
  conv <- if (record_convergence)
    data.frame(gen=integer(0), best_train=numeric(0), med_train=numeric(0),
               best_val=numeric(0),   med_val=numeric(0)) else NULL
  val_hist <- numeric(0)
  best_val_so_far <- Inf
  no_improve <- 0L
  
  # ======================== Bucle evolutivo ==============================
  for (gen in seq_len(generations)) {
    mut_rate     <- .ga_decay_mut(gen, generations, ctrl$mutation_rate_init)
    q95_seed_gen <- 1e6 + seed*1000 + gen
    
    # ---- Minibatch de escenarios (solo LIGHT Y solo si se pidió) --------
    train_sub <- train_idx
    if (identical(prepped_mode, "light") && !is.null(ctrl$minibatch_frac)) {
      k <- ceiling(length(train_idx) * ctrl$minibatch_frac)
      k <- max(ctrl$minibatch_min, min(k, length(train_idx)))
      seed_mb <- 9e6 + seed*1000 + gen
      train_sub <- balanced_sample_idx(prepped, train_idx, k, seed_mb)
    }
    
    # ---- Fitness para toda la población --------------------------------
    eval_fun <- function(w)
      .ga_eval_split(w, prepped, train_sub, ctrl, q95_seed = q95_seed_gen)
    
    fitness_scores <- if (!is.null(cl)) {
      unlist(parallel::parLapply(
        cl,
        X = seq_len(nrow(ga_population)),
        fun = function(i, pop) eval_fun(pop[i, ]),
        ga_population
      ))
    } else {
      apply(ga_population, 1, eval_fun)
    }
    
    # ---- Elitismo + selección + variación -------------------------------
    ord_fit <- order(fitness_scores)
    n_elite <- min(ctrl$elitism, nrow(ga_population))
    elites  <- ga_population[ord_fit[seq_len(n_elite)], , drop = FALSE]
    
    sel_idx  <- tournament_select(fitness_scores, nrow(ga_population),
                                  t_size = ctrl$t_size, replace = TRUE)
    selected <- ga_population[sel_idx, , drop = FALSE]
    
    n_off <- nrow(ga_population) - nrow(elites)
    offspring <- if (n_off > 0L) t(replicate(n_off, {
      p1 <- selected[base::sample(nrow(selected), 1L), ]
      p2 <- selected[base::sample(nrow(selected), 1L), ]
      mutate_weights(crossover(p1, p2), mutation_rate = mut_rate, alpha_mut = ctrl$alpha_mut)
    })) else matrix(numeric(0), 0, ncol(ga_population))
    
    ga_population <- rbind(elites, offspring)
    
    # ---- Inmigración periódica -----------------------------------------
    if (gen %% 15L == 0L && ctrl$immigrant_rate > 0) {
      m <- max(1L, floor(nrow(ga_population) * ctrl$immigrant_rate))
      worst <- order(fitness_scores, decreasing = TRUE)[seq_len(m)]
      ga_population[worst, ] <- init_population(length(worst), N_EST, alpha = ctrl$init_alpha)
    }
    
    # ---- Validación y early-stopping -----------------------------------
    if (gen %% ctrl$check_every == 0L || gen == generations) {
      best_idx <- which.min(fitness_scores)
      w_best   <- ga_population[best_idx, ]
      
      eval_on <- function(w, idx)
        .ga_eval_split(w, prepped, idx, ctrl, q95_seed = q95_seed_gen)
      
      best_train <- eval_on(w_best, train_idx)   # reporte (train completo)
      best_val   <- eval_on(w_best,   val_idx)   # val completo (nunca minibatch)
      
      if (record_convergence) {
        med_train <- stats::median(fitness_scores)
        probe_val <- sapply(base::sample(seq_len(nrow(ga_population)),
                                         min(20L, nrow(ga_population))),
                            function(i) eval_on(ga_population[i, ], val_idx))
        conv <- rbind(conv, data.frame(gen=gen, best_train=best_train, med_train=med_train,
                                       best_val=best_val,   med_val=stats::median(probe_val)))
      }
      
      val_hist <- c(val_hist, best_val)
      if (best_val < best_val_so_far - 1e-12) {
        best_val_so_far <- best_val
        no_improve <- 0L
      } else {
        no_improve <- no_improve + 1L
      }
      if (no_improve > 0L) mut_rate <- min(0.30, mut_rate * (1 + 0.10 * no_improve))
      
      cat(sprintf("[%-10s] Gen %3d | Train %.6g | Val %.6g | mut=%.3f | mode=%s%s\n",
                  dist_name, gen, best_train, best_val, mut_rate, prepped_mode,
                  if (!is.null(ctrl$minibatch_frac) && identical(prepped_mode, "light"))
                    sprintf(" (mb=%d/%d)", length(train_sub), length(train_idx)) else ""))
      
      if (gen >= 30L && should_stop(val_hist, patience = ctrl$patience, min_delta = ctrl$min_delta)) {
        message(sprintf("[%s] Early stopping at gen %d.", dist_name, gen))
        break
      }
    }
  }
  
  # ======================== Selección final ==============================
  q95_seed_final <- 2e6 + seed*1000 + 777
  eval_val <- function(w)
    .ga_eval_split(w, prepped, val_idx, ctrl, q95_seed = q95_seed_final)
  
  final_scores_val <- if (!is.null(cl)) {
    unlist(parallel::parLapply(
      cl,
      X = seq_len(nrow(ga_population)),
      fun = function(i, pop) eval_val(pop[i, ]),
      ga_population
    ))
  } else {
    apply(ga_population, 1, eval_val)
  }
  
  best_idx       <- which.min(final_scores_val)
  best_weights   <- ga_population[best_idx, , drop = FALSE]
  best_val_score <- min(final_scores_val)
  
  # Guardar warm-starts (top-k por validación)
  keep_k <- min(nrow(ga_population), max(10L, as.integer(ctrl$elitism)))
  set_warm_start(dist_name, seed, ga_population[order(final_scores_val)[seq_len(keep_k)], , drop = FALSE])
  
  # ======================== Resultados por escenario =====================
  scenario_rows <- lapply(seq_along(prepped), function(i) {
    S <- prepped[[i]]
    dplyr::bind_rows(lapply(sample_sizes, function(n)
      summarize_scenario(S, as.numeric(best_weights), dist_name, n,
                         q95_B = ctrl$bootstrap_B, q95_seed = q95_seed_final)))
  })
  scenario_df <- dplyr::bind_rows(scenario_rows)
  
  agg_by_est <- scenario_df %>%
    dplyr::group_by(estimator) %>%
    dplyr::summarise(mean_mse      = base::mean(mse, na.rm = TRUE),
                     q95_mse       = base::mean(mse_q95, na.rm = TRUE),
                     max_mse       = base::max(mse_max, na.rm = TRUE),
                     mean_bias     = base::mean(bias, na.rm = TRUE),
                     mean_variance = base::mean(variance, na.rm = TRUE),
                     .groups = "drop")
  robust_row <- dplyr::filter(agg_by_est, estimator == "robust")
  
  # =============================== OVERALL ===============================
  wcols <- as.list(round(as.numeric(best_weights), 6))
  names(wcols) <- paste0("w_", ESTIMATOR_NAMES)
  wdf <- as.data.frame(wcols, check.names = FALSE, stringsAsFactors = FALSE)
  
  topk_idx <- head(order(final_scores_val), 5L)
  base_df <- data.frame(
    distribution  = dist_name,
    objective     = ctrl$objective,
    estimator     = weights_to_formula(as.numeric(best_weights)),
    topk_formulas = paste(apply(ga_population[topk_idx, , drop = FALSE],
                                1, function(w) weights_to_formula(as.numeric(w))),
                          collapse = " || "),
    scenario_mode = prepped_mode,
    stringsAsFactors = FALSE
  )
  metrics_df <- data.frame(robust_mean_mse  = robust_row$mean_mse,
                           robust_q95_mse   = robust_row$q95_mse,
                           robust_max_mse   = robust_row$max_mse,
                           robust_mean_bias = robust_row$mean_bias,
                           stringsAsFactors = FALSE)
  overall <- cbind(base_df, wdf, metrics_df)
  
  list(weights        = as.numeric(best_weights),
       estimator_str  = weights_to_formula(as.numeric(best_weights)),
       topk_weights   = ga_population[topk_idx, , drop = FALSE],
       scenario_table = scenario_df,
       overall        = overall,
       convergence    = conv,
       best_val_score = if (return_val_best) best_val_score else NA_real_)
}

  

# =========================== GA con K-fold CV (K=3) ======================

evolve_universal_estimator_per_family_cv <- function(dist_name,
                                                     dist_param_grid,
                                                     sample_sizes = c(300, 500, 1000, 2000, 5000),
                                                     num_samples = 80,
                                                     pop_size = 100,
                                                     generations_per_fold = 35,
                                                     seed = 101,
                                                     objective = "q95",
                                                     use_parallel = TRUE,
                                                     k_folds = 3,
                                                     lambda_instab = 0.15,
                                                     bootstrap_B = 200L,
                                                     t_size = 2L,
                                                     elitism = 2L,
                                                     immigrant_rate = 0.10,
                                                     mutation_rate_init = 0.18,
                                                     init_alpha = 1.0,
                                                     alpha_mut = 1.0,
                                                     check_every = 5L,
                                                     patience = 3L,
                                                     min_delta = 0.005,
                                                     final_retrain = TRUE,
                                                     mix_w_q95 = 0.7,
                                                     mix_w_max = 0.3,
                                                     lambda_entropy = 0.015,
                                                     max_w_dominance = 0.80,
                                                     lambda_dominance = 0.05,
                                                     lambda_bias = 0.05,
                                                     minibatch_frac = NULL,
                                                     minibatch_min  = 12L,
                                                     crn_env = NULL,
                                                     fam_key = NULL,
                                                     # >>> NUEVO: forzar full/light desde fuera
                                                     force_scenario_mode = NULL) {
  stopifnot(length(sample_sizes) >= 1L, pop_size >= 2L, generations_per_fold >= 1L, k_folds >= 2L)
  set.seed(seed)
  
  # Si viene forzado, respétalo; si no, usa la heurística habitual
  scenario_mode <- if (!is.null(force_scenario_mode)) {
    match.arg(force_scenario_mode, c("full","light"))
  } else {
    .ga_pick_mode(sample_sizes, num_samples, pop_size, generations_per_fold)
  }
  
  prepped_ref <- prep_scenarios(
    dist_name, dist_param_grid,
    sample_sizes  = sample_sizes,
    num_samples   = num_samples,
    scenario_mode = scenario_mode,
    seed          = seed,
    crn_env       = crn_env,
    fam_key       = if (is.null(fam_key)) dist_name else fam_key
  )
  all_idx <- seq_along(prepped_ref)
  if (length(all_idx) < k_folds) {
    stop(sprintf("k_folds=%d es mayor que #escenarios=%d.", k_folds, length(all_idx)))
  }
  
  folds <- make_folds(length(all_idx), k = k_folds, seed = seed)
  fold_results <- vector("list", k_folds)
  warm_bank <- NULL
  
  run_fold <- function(train_idx, val_idx, seed_fold, warm_mat, gens, pop_sz, retrain_all = FALSE) {
    evolve_universal_estimator_per_family(
      dist_name          = dist_name,
      dist_param_grid    = dist_param_grid,
      sample_sizes       = sample_sizes,
      num_samples        = num_samples,
      pop_size           = pop_sz,
      generations        = gens,
      seed               = seed_fold,
      objective          = objective,
      use_parallel       = use_parallel,
      train_idx          = train_idx,
      val_idx            = val_idx,
      lambda_instab      = lambda_instab,
      bootstrap_B        = bootstrap_B,
      t_size             = t_size,
      elitism            = elitism,
      immigrant_rate     = immigrant_rate,
      mutation_rate_init = mutation_rate_init,
      init_alpha         = init_alpha,
      alpha_mut          = alpha_mut,
      check_every        = check_every,
      patience           = patience,
      min_delta          = min_delta,
      warm_start_matrix  = warm_mat,
      return_val_best    = !retrain_all,
      mix_w_q95          = mix_w_q95,
      mix_w_max          = mix_w_max,
      lambda_entropy     = lambda_entropy,
      max_w_dominance    = max_w_dominance,
      lambda_dominance   = lambda_dominance,
      lambda_bias        = lambda_bias,
      minibatch_frac     = minibatch_frac,
      minibatch_min      = minibatch_min,
      crn_env            = crn_env,
      fam_key            = if (is.null(fam_key)) dist_name else fam_key,
      # >>> NUEVO: pásalo al GA single-split
      force_scenario_mode = force_scenario_mode
    )
  }
  
  for (k in seq_len(k_folds)) {
    val_idx   <- sort(unlist(folds[[k]]))
    train_idx <- sort(setdiff(all_idx, val_idx))
    cat(sprintf("\n[%s] Fold %d/%d | Train=%d | Val=%d | mode=%s\n",
                dist_name, k, k_folds, length(train_idx), length(val_idx), scenario_mode))
    res_k <- run_fold(train_idx, val_idx, seed + k, warm_bank,
                      gens = generations_per_fold, pop_sz = pop_size)
    fold_results[[k]] <- res_k
    warm_bank <- rbind(warm_bank, res_k$weights)
  }
  
  val_scores <- vapply(fold_results, function(x) x$best_val_score %||% Inf, numeric(1))
  best_fold <- which.min(val_scores)
  best_weights_cv <- fold_results[[best_fold]]$weights
  
  if (isTRUE(final_retrain)) {
    cat(sprintf("\n[%s] Final retrain on ALL scenarios (warm-start)\n", dist_name))
    res_final <- run_fold(
      train_idx  = all_idx,
      val_idx    = all_idx,
      seed_fold  = seed + 999,
      warm_mat   = rbind(warm_bank, best_weights_cv),
      gens       = max(40L, as.integer(generations_per_fold)),
      pop_sz     = max(60L, as.integer(pop_size)),
      retrain_all = TRUE
    )
    return(list(fold_results = fold_results, final = res_final))
  } else {
    return(list(fold_results = fold_results, final = fold_results[[best_fold]]))
  }
}


# ============================== SAVE HELPERS ==============================

# Utilitario: escribir CSV solo si el objeto existe y tiene filas
.write_csv_safe <- function(obj, path) {
  if (is.null(obj)) return(invisible(FALSE))
  if (!is.data.frame(obj) || nrow(obj) == 0L) return(invisible(FALSE))
  readr::write_csv(obj, path)
  invisible(TRUE)
}

# Guardado detallado por configuración/familia (opcional)
save_family_config_outputs <- function(root_out, family_tag, config_tag, res_cv) {
  if (is.null(res_cv) || is.null(res_cv$final)) return(invisible(FALSE))
  fam_dir   <- file.path(root_out, family_tag)
  folds_dir <- file.path(fam_dir, sprintf("FOLDS__%s", config_tag))
  mkdirp(fam_dir); mkdirp(folds_dir)
  
  # --- Final (retrain o mejor fold) ---
  .write_csv_safe(res_cv$final$overall,
                  file.path(fam_dir, sprintf("OVERALL__%s.csv",   config_tag)))
  .write_csv_safe(res_cv$final$scenario_table,
                  file.path(fam_dir, sprintf("SCENARIOS__%s.csv", config_tag)))
  .write_csv_safe(res_cv$final$convergence,
                  file.path(fam_dir, sprintf("CONVERGENCE__%s.csv", config_tag)))
  
  # --- Por fold ---
  fr_list <- res_cv$fold_results %||% list()
  if (length(fr_list) > 0) {
    for (k in seq_along(fr_list)) {
      fr <- fr_list[[k]]
      .write_csv_safe(fr$overall,        file.path(folds_dir, sprintf("fold%02d_OVERALL.csv",    k)))
      .write_csv_safe(fr$scenario_table, file.path(folds_dir, sprintf("fold%02d_SCENARIOS.csv",  k)))
      .write_csv_safe(fr$convergence,    file.path(folds_dir, sprintf("fold%02d_CONVERGENCE.csv", k)))
    }
  }
  invisible(TRUE)
}

# ====================== LAUNCHER: TODO EN UNA TIRADA ======================

run_all_one_shot <- function(
    families_to_run = c("lognormal","weibull"),
    pop_sizes       = c(80, 100),
    mutation_rates  = c(0.12, 0.18, 0.24),
    init_alphas     = c(0.5, 1.0),
    alpha_mut_set   = c(0.5, 1.0),
    immigrant_rates = c(0.05, 0.10),
    t_sizes         = c(2L, 3L),
    elitism_set     = c(1L, 2L),
    seeds           = c(101, 202),
    
    # GA/scenarios (tu existente)
    sample_sizes = c(300, 500, 1000, 2000, 5000),
    num_samples  = 80,
    generations_per_fold = 60,
    k_folds = 3,
    final_retrain = TRUE,
    objective    = "q95",
    lambda_instab_default = 0.15,
    bootstrap_B  = 200L,
    check_every  = 5L,
    patience     = 3L,
    min_delta    = 0.005,
    use_parallel = TRUE,
    mix_w_q95 = 0.7, mix_w_max = 0.3,
    out_root = ".",
    minibatch_frac = 0.5,
    minibatch_min  = 8L,
    pick_single_winner_per_family = TRUE,
    suppress_intermediate_saves   = TRUE,
    winner_metric = c("robust_q95_mse","robust_mean_mse","robust_max_mse"),
    
    # >>> Estrategia de búsqueda
    search_strategy = c("grid","random","halving"),
    random_n = 40,
    eta = 3,                   # halving reduction factor
    finalists_per_family = 2,  # cuántos empujar a “full grind”
    
    # >>> Schedules para HALVING (multi-fidelity, FASE 3)
    # Early stages = menor presupuesto y menos muestras para velocidad
    stage_gens_frac = c(0.25, 0.60, 1.00),
    stage_pop_size  = c(40,   60,   NA),  # NA -> usa max(pop_sizes)
    stage_num_samples = c(30,  60,   NA), # NA -> usa full num_samples
    stage_bootstrap_B = c(60L, 100L, NA), # NA -> usa full bootstrap_B
    
    # >>> NUEVO: FASES ESTRICTAS DEL GRIND DE HP (FASE 1 y FASE 2)
    hp_strict = TRUE,            # activa Fase 1 + Fase 2 strict
    # Fase 1 (minibatch de configs + minibatch de escenarios)
    hp1_frac = 0.25,             # o usa hp1_k exacto
    hp1_k    = NULL,
    hp1_gens = 10L,
    hp1_num_samples = NULL,      # por defecto: round(0.4 * num_samples)
    hp1_bootstrap_B = NULL,      # por defecto: round(0.33 * bootstrap_B)
    hp1_minibatch_frac = 0.50,   # minibatch de escenarios (solo si modo=light)
    hp1_minibatch_min  = 10L,
    # Fase 2 (top-K + más presupuesto, aún con minibatch de escenarios)
    hp2_k    = 20L,              # top-K exacto tras F1
    hp2_gens = 20L,
    hp2_num_samples = NULL,      # por defecto: round(0.6 * num_samples)
    hp2_bootstrap_B = NULL,      # por defecto: round(0.6 * bootstrap_B)
    hp2_minibatch_frac = 0.50,
    hp2_minibatch_min  = 12L,
    # Pool que pasa a Fase 3 (HALVING)
    hp3_pool_k = 10L             # “8–10 mejores” típico; ajusta aquí
) {
  run_id  <- paste0("GA_UNIFIED_", RUN_TS())
  root_out <- file.path(out_root, run_id); mkdirp(root_out)
  
  # === NEW: acumulador para la mega-CSV ===
  biglog <- list()
  
  # --- MANIFEST enriquecido ---
  search_strategy <- match.arg(search_strategy)
  winner_metric   <- match.arg(winner_metric)
  meta <- list(
    run_id = run_id,
    families = families_to_run,
    k_folds = k_folds,
    objective = objective,
    seeds = paste(seeds, collapse = ","),
    pop_sizes = pop_sizes,
    generations_per_fold = generations_per_fold,
    final_retrain = final_retrain,
    bootstrap_B = bootstrap_B,
    lambda_instab_default = lambda_instab_default,
    mutation_rates = mutation_rates,
    init_alphas = init_alphas,
    alpha_mut_set = alpha_mut_set,
    immigrant_rates = immigrant_rates,
    t_sizes = t_sizes,
    elitism_set = elitism_set,
    minibatch_frac = minibatch_frac,
    minibatch_min = minibatch_min,
    scenario_mode = "auto",
    search_strategy = search_strategy,
    random_n = random_n,
    eta = eta,
    finalists_per_family = finalists_per_family,
    stage_gens_frac = stage_gens_frac,
    stage_pop_size  = stage_pop_size,
    stage_num_samples = stage_num_samples,
    stage_bootstrap_B = stage_bootstrap_B,
    winner_metric = winner_metric,
    pick_single_winner_per_family = pick_single_winner_per_family,
    # HP strict manifest
    hp_strict = hp_strict,
    hp1_frac = hp1_frac, hp1_k = hp1_k, hp1_gens = hp1_gens,
    hp1_num_samples = hp1_num_samples, hp1_bootstrap_B = hp1_bootstrap_B,
    hp1_minibatch_frac = hp1_minibatch_frac, hp1_minibatch_min = hp1_minibatch_min,
    hp2_k = hp2_k, hp2_gens = hp2_gens,
    hp2_num_samples = hp2_num_samples, hp2_bootstrap_B = hp2_bootstrap_B,
    hp2_minibatch_frac = hp2_minibatch_frac, hp2_minibatch_min = hp2_minibatch_min,
    hp3_pool_k = hp3_pool_k
  )
  write_manifest(root_out, meta)
  # === Enforce mínimos de 40 gens para Fase 1 y Fase 2 ===
  hp1_gens <- max(40L, as.integer(hp1_gens))
  hp2_gens <- max(40L, as.integer(hp2_gens))
  
  # ---- CRN ----
  crn_env <- make_crn_indices(
    families     = families_to_run,
    sample_sizes = sample_sizes,
    B_boot       = bootstrap_B,
    num_samples  = num_samples
  )
  
  # Grid de hiperparámetros candidatos
  cfg_grid <- expand.grid(
    pop_size           = pop_sizes,
    mutation_rate_init = mutation_rates,
    init_alpha         = init_alphas,
    alpha_mut          = alpha_mut_set,
    immigrant_rate     = immigrant_rates,
    t_size             = t_sizes,
    elitism            = elitism_set,
    seed               = seeds,
    lambda_instab      = lambda_instab_default,
    stringsAsFactors   = FALSE
  )
  
  # ---- Planificador de pasos para mostrar 1-100% --------------------------
  .plan_family_steps <- function(n_cfg) {
    if (search_strategy != "halving") return(as.integer(n_cfg))  # 1 eval por config
    
    # F1/F2 si hp_strict
    n1 <- if (isTRUE(hp_strict)) {
      if (!is.null(hp1_k)) min(hp1_k, n_cfg) else ceiling(n_cfg * hp1_frac)
    } else 0
    n1 <- as.integer(n1)
    
    n2 <- if (isTRUE(hp_strict)) {
      if (!is.null(hp2_k)) min(hp2_k, n1) else ceiling(n1 * 0.33)
    } else n_cfg
    n2 <- as.integer(n2)
    
    start_halv <- if (isTRUE(hp_strict)) min(hp3_pool_k, n2) else n2
    start_halv <- as.integer(start_halv)
    
    S <- length(stage_gens_frac)
    cur <- start_halv
    n_halv <- 0L
    for (s in seq_len(S)) {
      n_halv <- n_halv + max(0L, as.integer(cur))
      cur <- if (s < S) max(1L, as.integer(ceiling(cur / eta))) else as.integer(finalists_per_family)
    }
    n_final <- as.integer(finalists_per_family)
    
    as.integer(n1 + n2 + n_halv + n_final)
  }
  
  
  total_steps <- sum(vapply(families_to_run, function(fam) .plan_family_steps(nrow(cfg_grid)), integer(1)))
  progress_init(total_steps)
  
  # ======== util interno: score de etapa (q95 val con fallback) =========
  .stage_score <- function(res_cv) {
    s <- res_cv$final$best_val_score
    if (!is.finite(s)) {
      ov <- res_cv$final$overall
      s <- ov$robust_q95_mse[1]
    }
    s
  }
  
  # ======== Selección/ajustes de estrategia de búsqueda ==================
  if (search_strategy == "random") {
    set.seed(13)
    if (nrow(cfg_grid) > random_n) {
      cfg_grid <- cfg_grid[sample(seq_len(nrow(cfg_grid)), random_n), , drop = FALSE]
    }
  }
  if (search_strategy == "halving") {
    S <- length(stage_gens_frac)
    stopifnot(length(stage_pop_size)   == S,
              length(stage_num_samples)== S,
              length(stage_bootstrap_B)== S)
  }
  
  # ======== Acumuladores =================================================
  big_rows <- list()   # para incluir el rollup dentro de la mega-CSV
  winners_df <- NULL
  
  # ============================== LOOP FAMILIAS ==========================
  for (dist in families_to_run) {
    message(sprintf("\n========== FAMILY: %s ==========\n", dist))
    grid <- param_grids[[dist]]
    fam_pool <- cfg_grid  # candidatos iniciales
    
    if (search_strategy != "halving") {
      # ===================== PATH ORIGINAL (grid/random) =================
      for (i in seq_len(nrow(fam_pool))) {
        cfg <- fam_pool[i, ]
        config_tag <- sprintf("ps%d_mr%.2f_a0%.2f_am%.2f_im%.2f_t%d_e%d_seed%d",
                              cfg$pop_size, cfg$mutation_rate_init, cfg$init_alpha, cfg$alpha_mut,
                              cfg$immigrant_rate, cfg$t_size, cfg$elitism, cfg$seed)
        cat(sprintf("[RUN] %s | %s\n", dist, config_tag))
        
        res_cv <- do.call(
          evolve_universal_estimator_per_family_cv,
          c(list(
            dist_name            = dist,
            dist_param_grid      = grid,
            pop_size             = cfg$pop_size,
            generations_per_fold = generations_per_fold,
            seed                 = cfg$seed,
            objective            = objective,
            use_parallel         = use_parallel,
            k_folds              = k_folds,
            lambda_instab        = cfg$lambda_instab,
            bootstrap_B          = bootstrap_B,
            t_size               = cfg$t_size,
            elitism              = cfg$elitism,
            immigrant_rate       = cfg$immigrant_rate,
            mutation_rate_init   = cfg$mutation_rate_init,
            init_alpha           = cfg$init_alpha,
            alpha_mut            = cfg$alpha_mut,
            check_every          = check_every,
            patience             = patience,
            min_delta            = min_delta,
            final_retrain        = TRUE,
            mix_w_q95            = mix_w_q95,
            mix_w_max            = mix_w_max,
            # respeta heurístico de escenarios (no forzamos)
            minibatch_frac       = minibatch_frac,
            minibatch_min        = minibatch_min,
            crn_env              = crn_env,
            fam_key              = dist,
            sample_sizes         = sample_sizes,
            num_samples          = num_samples,
            force_scenario_mode  = NULL
          ))
        )
        progress_step(sprintf("ORIGINAL %s | %s", dist, config_tag))
        
        # === NEW: log a la mega-CSV con contexto de fase/budget/cobertura ===
        ov <- res_cv$final$overall
        ctx <- list(
          phase = "ORIGINAL", grind_stage = NA_integer_,
          budget_gens = generations_per_fold, budget_pop = cfg$pop_size,
          used_num_samples = num_samples, used_bootstrapB = bootstrap_B,
          objective = objective,
          scenario_mode = ov$scenario_mode[1],
          coverage_hint = ifelse(tolower(ov$scenario_mode[1]) == "full", "full", "partial")
        )
        biglog <- .collect_from_cv(biglog, res_cv, run_id, dist, config_tag, is_winner = FALSE, context = ctx)
        
        if (!isTRUE(suppress_intermediate_saves)) {
          try(save_family_config_outputs(root_out, dist, config_tag, res_cv), silent = TRUE)
        }
        
        row <- data.frame(
          family          = dist,
          config_tag      = config_tag,
          stage           = 1L,
          is_finalist     = TRUE,
          budget_gens     = generations_per_fold,
          budget_pop      = cfg$pop_size,
          used_num_samples= num_samples,
          used_bootstrapB = bootstrap_B,
          objective       = objective,
          scenario_mode   = ov$scenario_mode[1],
          estimator       = ov$estimator[1],
          robust_mean_mse_final = ov$robust_mean_mse[1],
          robust_q95_mse_final  = ov$robust_q95_mse[1],
          robust_max_mse_final  = ov$robust_max_mse[1],
          delta_mean_mse  = NA_real_,
          delta_q95_mse   = NA_real_,
          delta_max_mse   = NA_real_,
          stringsAsFactors = FALSE
        )
        
        big_rows[[length(big_rows)+1L]] <- row
      }
      
    } else {
      # ===================== NUEVO: FASE 1 (HP STRICT) ===================
      if (isTRUE(hp_strict)) {
        hp1_ns <- hp1_num_samples %||% max(1L, round(0.4 * num_samples))
        hp1_B  <- hp1_bootstrap_B %||% max(20L, round(0.33 * bootstrap_B))
        
        fam_pool_phase1 <- if (!is.null(hp1_k)) {
          pick_minibatch_configs(fam_pool, k = hp1_k, seed = 13,
                                 stratify_cols = c("pop_size","t_size"))
        } else {
          pick_minibatch_configs(fam_pool, frac = hp1_frac, seed = 13,
                                 stratify_cols = c("pop_size","t_size"))
        }
        
        message(sprintf("[HP-F1] %s | configs=%d | gens=%d | ns=%d | B=%d",
                        dist, nrow(fam_pool_phase1), hp1_gens, hp1_ns, hp1_B))
        
        phase1_rows <- vector("list", nrow(fam_pool_phase1))
        for (i in seq_len(nrow(fam_pool_phase1))) {
          cfg <- fam_pool_phase1[i, ]
          tag <- sprintf("HPF1__ps%d_mr%.2f_a0%.2f_am%.2f_im%.2f_t%d_e%d_seed%d",
                         cfg$pop_size, cfg$mutation_rate_init, cfg$init_alpha, cfg$alpha_mut,
                         cfg$immigrant_rate, cfg$t_size, cfg$elitism, cfg$seed)
          
          res1 <- do.call(
            evolve_universal_estimator_per_family_cv,
            c(list(
              dist_name            = dist,
              dist_param_grid      = grid,
              pop_size             = cfg$pop_size,
              generations_per_fold = hp1_gens,
              seed                 = cfg$seed,
              objective            = objective,
              use_parallel         = use_parallel,
              k_folds              = k_folds,
              lambda_instab        = cfg$lambda_instab,
              bootstrap_B          = hp1_B,
              t_size               = cfg$t_size,
              elitism              = cfg$elitism,
              immigrant_rate       = cfg$immigrant_rate,
              mutation_rate_init   = cfg$mutation_rate_init,
              init_alpha           = cfg$init_alpha,
              alpha_mut            = cfg$alpha_mut,
              check_every          = check_every,
              patience             = patience,
              min_delta            = min_delta,
              final_retrain        = FALSE,
              mix_w_q95            = mix_w_q95,
              mix_w_max            = mix_w_max,
              # minibatch de escenarios SOLO si el modo es light
              minibatch_frac       = hp1_minibatch_frac,
              minibatch_min        = hp1_minibatch_min,
              crn_env              = crn_env,
              fam_key              = dist,
              sample_sizes         = sample_sizes,
              num_samples          = hp1_ns,
              # F1: no se fuerza modo; dejamos heurístico de escenarios
              force_scenario_mode  = NULL
            ))
          )
          progress_step(sprintf("HPF1 %s | %s", dist, tag))
          # === NEW: log de F1 ===
          ov <- res1$final$overall
          ctx <- list(
            phase = "HPF1", grind_stage = 1L,
            budget_gens = hp1_gens, budget_pop = cfg$pop_size,
            used_num_samples = hp1_ns, used_bootstrapB = hp1_B,
            objective = objective,
            scenario_mode = ov$scenario_mode[1],
            coverage_hint = ifelse(tolower(ov$scenario_mode[1]) == "full", "full", "partial")
          )
          biglog <- .collect_from_cv(biglog, res1, run_id, dist, tag, is_winner = FALSE, context = ctx)
          
          sc <- .stage_score(res1)
          phase1_rows[[i]] <- data.frame(
            family          = dist,
            config_tag      = tag,
            stage           = 1L,
            is_finalist     = FALSE,
            budget_gens     = hp1_gens,
            budget_pop      = cfg$pop_size,
            used_num_samples= hp1_ns,
            used_bootstrapB = hp1_B,
            objective       = objective,
            scenario_mode   = ov$scenario_mode[1],
            estimator       = ov$estimator[1],
            score_stage     = sc,
            robust_mean_mse_stage = ov$robust_mean_mse[1],
            robust_q95_mse_stage  = ov$robust_q95_mse[1],
            robust_max_mse_stage  = ov$robust_max_mse[1],
            # === NUEVO: también guarda “finales” en parciales ===
            robust_mean_mse_final = ov$robust_mean_mse[1],
            robust_q95_mse_final  = ov$robust_q95_mse[1],
            robust_max_mse_final  = ov$robust_max_mse[1],
            stringsAsFactors = FALSE
          )
          
        }
        big_rows <- c(big_rows, phase1_rows)
        
        df1  <- dplyr::bind_rows(phase1_rows)
        ord1 <- order(df1$score_stage)
        keep1 <- if (!is.null(hp2_k)) min(hp2_k, nrow(df1)) else ceiling(nrow(df1) * 0.33)
        keep1 <- max(1L, keep1)
        fam_pool <- fam_pool_phase1[ord1[seq_len(keep1)], , drop = FALSE]
        if (!nrow(fam_pool)) stop("[HP-F1] filtro dejó 0 configs.")
      }
      
      # ===================== NUEVO: FASE 2 (HP STRICT) ===================
      if (isTRUE(hp_strict)) {
        hp2_ns <- hp2_num_samples %||% max(1L, round(0.6 * num_samples))
        hp2_B  <- hp2_bootstrap_B %||% max(40L, round(0.6 * bootstrap_B))
        
        message(sprintf("[HP-F2] %s | configs=%d | gens=%d | ns=%d | B=%d",
                        dist, nrow(fam_pool), hp2_gens, hp2_ns, hp2_B))
        
        phase2_rows <- vector("list", nrow(fam_pool))
        for (i in seq_len(nrow(fam_pool))) {
          cfg <- fam_pool[i, ]
          tag <- sprintf("HPF2__ps%d_mr%.2f_a0%.2f_am%.2f_im%.2f_t%d_e%d_seed%d",
                         cfg$pop_size, cfg$mutation_rate_init, cfg$init_alpha, cfg$alpha_mut,
                         cfg$immigrant_rate, cfg$t_size, cfg$elitism, cfg$seed)
          
          res2 <- do.call(
            evolve_universal_estimator_per_family_cv,
            c(list(
              dist_name            = dist,
              dist_param_grid      = grid,
              pop_size             = cfg$pop_size,
              generations_per_fold = hp2_gens,
              seed                 = cfg$seed,
              objective            = objective,
              use_parallel         = use_parallel,
              k_folds              = k_folds,
              lambda_instab        = cfg$lambda_instab,
              bootstrap_B          = hp2_B,
              t_size               = cfg$t_size,
              elitism              = cfg$elitism,
              immigrant_rate       = cfg$immigrant_rate,
              mutation_rate_init   = cfg$mutation_rate_init,
              init_alpha           = cfg$init_alpha,
              alpha_mut            = cfg$alpha_mut,
              check_every          = check_every,
              patience             = patience,
              min_delta            = min_delta,
              final_retrain        = FALSE,
              mix_w_q95            = mix_w_q95,
              mix_w_max            = mix_w_max,
              minibatch_frac       = hp2_minibatch_frac,
              minibatch_min        = hp2_minibatch_min,
              crn_env              = crn_env,
              fam_key              = dist,
              sample_sizes         = sample_sizes,
              num_samples          = hp2_ns,
              force_scenario_mode  = NULL
            ))
          )
          progress_step(sprintf("HPF2 %s | %s", dist, tag))
          # === NEW: log de F2 ===
          ov <- res2$final$overall
          ctx <- list(
            phase = "HPF2", grind_stage = 2L,
            budget_gens = hp2_gens, budget_pop = cfg$pop_size,
            used_num_samples = hp2_ns, used_bootstrapB = hp2_B,
            objective = objective,
            scenario_mode = ov$scenario_mode[1],
            coverage_hint = ifelse(tolower(ov$scenario_mode[1]) == "full", "full", "partial")
          )
          biglog <- .collect_from_cv(biglog, res2, run_id, dist, tag, is_winner = FALSE, context = ctx)
          
          sc <- .stage_score(res2)
          phase2_rows[[i]] <- data.frame(
            family          = dist,
            config_tag      = tag,
            stage           = 2L,
            is_finalist     = FALSE,
            budget_gens     = hp2_gens,
            budget_pop      = cfg$pop_size,
            used_num_samples= hp2_ns,
            used_bootstrapB = hp2_B,
            objective       = objective,
            scenario_mode   = ov$scenario_mode[1],
            estimator       = ov$estimator[1],
            score_stage     = sc,
            robust_mean_mse_stage = ov$robust_mean_mse[1],
            robust_q95_mse_stage  = ov$robust_q95_mse[1],
            robust_max_mse_stage  = ov$robust_max_mse[1],
            # === NUEVO: “finales” en parciales ===
            robust_mean_mse_final = ov$robust_mean_mse[1],
            robust_q95_mse_final  = ov$robust_q95_mse[1],
            robust_max_mse_final  = ov$robust_max_mse[1],
            stringsAsFactors = FALSE
          )
          
        }
        big_rows <- c(big_rows, phase2_rows)
        
        df2  <- dplyr::bind_rows(phase2_rows)
        ord2 <- order(df2$score_stage)
        keep2 <- max(1L, min(hp3_pool_k, nrow(df2)))
        fam_pool <- fam_pool[ord2[seq_len(keep2)], , drop = FALSE]
        if (!nrow(fam_pool)) stop("[HP-F2] filtro dejó 0 configs.")
      }
      
      # ===================== FASE 3: HALVING (full scenarios) =============
      S <- length(stage_gens_frac)
      for (s in seq_len(S)) {
        gens_s <- max(30L, ceiling(generations_per_fold * stage_gens_frac[s]))
        pop_s  <- if (is.na(stage_pop_size[s]))  max(pop_sizes)  else stage_pop_size[s]
        num_s  <- if (is.na(stage_num_samples[s])) num_samples   else stage_num_samples[s]
        B_s    <- if (is.na(stage_bootstrap_B[s])) bootstrap_B   else stage_bootstrap_B[s]
        
        message(sprintf("[HALVING] %s | Stage %d/%d | candidates=%d | budget: gens=%d, pop=%d, num_samples=%d, B=%d",
                        dist, s, S, nrow(fam_pool), gens_s, pop_s, num_s, B_s))
        
        stage_eval <- vector("list", nrow(fam_pool))
        for (i in seq_len(nrow(fam_pool))) {
          cfg <- fam_pool[i, ]
          config_tag <- sprintf("ps%d_mr%.2f_a0%.2f_am%.2f_im%.2f_t%d_e%d_seed%d_STAGE%d",
                                pop_s, cfg$mutation_rate_init, cfg$init_alpha, cfg$alpha_mut,
                                cfg$immigrant_rate, cfg$t_size, cfg$elitism, cfg$seed, s)
          cat(sprintf("[RUN] %s | %s\n", dist, config_tag))
          
          res_cv <- do.call(
            evolve_universal_estimator_per_family_cv,
            c(list(
              dist_name            = dist,
              dist_param_grid      = grid,
              pop_size             = pop_s,
              generations_per_fold = gens_s,
              seed                 = cfg$seed,
              objective            = objective,
              use_parallel         = use_parallel,
              k_folds              = k_folds,
              lambda_instab        = cfg$lambda_instab,
              bootstrap_B          = B_s,
              t_size               = cfg$t_size,
              elitism              = cfg$elitism,
              immigrant_rate       = cfg$immigrant_rate,
              mutation_rate_init   = cfg$mutation_rate_init,
              init_alpha           = cfg$init_alpha,
              alpha_mut            = cfg$alpha_mut,
              check_every          = check_every,
              patience             = patience,
              min_delta            = min_delta,
              final_retrain        = FALSE,  # no consolidar en stages
              mix_w_q95            = mix_w_q95,
              mix_w_max            = mix_w_max,
              # MUY IMPORTANTE: sin minibatch de escenarios en HALVING
              minibatch_frac       = NULL,
              minibatch_min        = minibatch_min,
              crn_env              = crn_env,
              fam_key              = dist,
              sample_sizes         = sample_sizes,
              num_samples          = num_s,
              # MUY IMPORTANTE: forzar FULL en HALVING
              force_scenario_mode  = "full"
            ))
          )
          progress_step(sprintf("HALVING S%d %s | %s", s, dist, config_tag))
          if (!isTRUE(suppress_intermediate_saves)) {
            ov_tmp <- res_cv$final$overall
            .write_csv_safe(ov_tmp, file.path(root_out, dist,
                                              sprintf("STAGE%d__%s__OVERALL.csv", s, config_tag)))
          }
          
          # === NEW: log de HALVING (siempre full) ===
          ov <- res_cv$final$overall
          ctx <- list(
            phase = "HALVING", grind_stage = as.integer(s),
            budget_gens = gens_s, budget_pop = pop_s,
            used_num_samples = num_s, used_bootstrapB = B_s,
            objective = objective,
            scenario_mode = "full", coverage_hint = "full"
          )
          biglog <- .collect_from_cv(biglog, res_cv, run_id, dist, config_tag, is_winner = FALSE, context = ctx)
          
          score <- .stage_score(res_cv)
          row <- data.frame(
            family          = dist,
            config_tag      = config_tag,
            stage           = s,
            is_finalist     = FALSE,
            budget_gens     = gens_s,
            budget_pop      = pop_s,
            used_num_samples= num_s,
            used_bootstrapB = B_s,
            objective       = objective,
            scenario_mode   = ov$scenario_mode[1],
            estimator       = ov$estimator[1],
            score_stage     = score,
            robust_mean_mse_stage = ov$robust_mean_mse[1],
            robust_q95_mse_stage  = ov$robust_q95_mse[1],
            robust_max_mse_stage  = ov$robust_max_mse[1],
            # === NUEVO: “finales” en parciales ===
            robust_mean_mse_final = ov$robust_mean_mse[1],
            robust_q95_mse_final  = ov$robust_q95_mse[1],
            robust_max_mse_final  = ov$robust_max_mse[1],
            stringsAsFactors = FALSE
          )
          
          
          big_rows[[length(big_rows)+1L]] <- row
          stage_eval[[i]] <- list(score=score, cfg=cfg)
        }
        
        scores <- vapply(stage_eval, `[[`, numeric(1), "score")
        keep_n <- if (s < S) max(1L, ceiling(nrow(fam_pool) / eta))
        else max(finalists_per_family, 1L)
        keep_ix <- order(scores)[seq_len(min(keep_n, length(scores)))]
        fam_pool <- do.call(rbind, lapply(stage_eval[keep_ix], `[[`, "cfg"))
        fam_pool <- as.data.frame(fam_pool, stringsAsFactors = FALSE)
      }
      
      # ===================== FINAL: FULL GRIND SOBRE FINALISTAS ===========
      for (i in seq_len(nrow(fam_pool))) {
        cfg <- fam_pool[i, ]
        config_tag <- sprintf("FINAL__ps%d_mr%.2f_a0%.2f_am%.2f_im%.2f_t%d_e%d_seed%d",
                              max(pop_sizes), cfg$mutation_rate_init, cfg$init_alpha, cfg$alpha_mut,
                              cfg$immigrant_rate, cfg$t_size, cfg$elitism, cfg$seed)
        message(sprintf("[FINAL FULL GRIND] %s | %s", dist, config_tag))
        
        res_final <- do.call(
          evolve_universal_estimator_per_family_cv,
          c(list(
            dist_name            = dist,
            dist_param_grid      = grid,
            pop_size             = max(pop_sizes),
            generations_per_fold = generations_per_fold,
            seed                 = cfg$seed,
            objective            = objective,
            use_parallel         = use_parallel,
            k_folds              = k_folds,
            lambda_instab        = cfg$lambda_instab,
            bootstrap_B          = bootstrap_B,
            t_size               = cfg$t_size,
            elitism              = cfg$elitism,
            immigrant_rate       = cfg$immigrant_rate,
            mutation_rate_init   = cfg$mutation_rate_init,
            init_alpha           = cfg$init_alpha,
            alpha_mut            = cfg$alpha_mut,
            check_every          = check_every,
            patience             = patience,
            min_delta            = min_delta,
            final_retrain        = TRUE,  # consolidar en todos los escenarios
            mix_w_q95            = mix_w_q95,
            mix_w_max            = mix_w_max,
            # SIN minibatch de escenarios en el final full
            minibatch_frac       = NULL,
            minibatch_min        = minibatch_min,
            crn_env              = crn_env,
            fam_key              = dist,
            sample_sizes         = sample_sizes,
            num_samples          = num_samples,
            force_scenario_mode  = "full"
          ))
        )
        progress_step(sprintf("FINAL %s | %s", dist, config_tag))
        # === NEW: log del FINAL (full) ===
        ov_f <- res_final$final$overall
        ctx <- list(
          phase = "FINAL", grind_stage = length(stage_gens_frac),
          budget_gens = generations_per_fold, budget_pop = max(pop_sizes),
          used_num_samples = num_samples, used_bootstrapB = bootstrap_B,
          objective = objective,
          scenario_mode = "full", coverage_hint = "full"
        )
        biglog <- .collect_from_cv(biglog, res_final, run_id, dist, config_tag, is_winner = FALSE, context = ctx)
        
        if (!isTRUE(suppress_intermediate_saves)) {
          try(save_family_config_outputs(root_out, dist, config_tag, res_final), silent = TRUE)
        }
        
        # Buscar fila de última etapa (para deltas, best-effort por seed)
        S_last <- length(stage_gens_frac)
        stage_rows <- which(vapply(big_rows, function(r) {
          isTRUE(r$family == dist) &&
            isTRUE(grepl("_STAGE\\d+$", r$config_tag)) &&
            isTRUE(r$stage == S_last) &&
            isTRUE(grepl(sprintf("seed%d", cfg$seed), r$config_tag))
        }, logical(1)))
        delta_mean <- delta_q95 <- delta_max <- NA_real_
        if (length(stage_rows) > 0) {
          rlast <- big_rows[[tail(stage_rows, 1)]]
          delta_mean <- ov_f$robust_mean_mse[1] - rlast$robust_mean_mse_stage
          delta_q95  <- ov_f$robust_q95_mse[1]  - rlast$robust_q95_mse_stage
          delta_max  <- ov_f$robust_max_mse[1]  - rlast$robust_max_mse_stage
        }
        
        row_final <- data.frame(
          family          = dist,
          config_tag      = config_tag,
          stage           = S_last,
          is_finalist     = TRUE,
          budget_gens     = generations_per_fold,
          budget_pop      = max(pop_sizes),
          used_num_samples= num_samples,
          used_bootstrapB = bootstrap_B,
          objective       = objective,
          scenario_mode   = ov_f$scenario_mode[1],
          estimator       = ov_f$estimator[1],
          robust_mean_mse_final = ov_f$robust_mean_mse[1],
          robust_q95_mse_final  = ov_f$robust_q95_mse[1],
          robust_max_mse_final  = ov_f$robust_max_mse[1],
          delta_mean_mse  = delta_mean,
          delta_q95_mse   = delta_q95,
          delta_max_mse   = delta_max,
          stringsAsFactors = FALSE
        )
        
        big_rows[[length(big_rows)+1L]] <- row_final
      }
    } # end halving path
  } # end families loop
  
  # ======== INCRUSTAR ROLLUP Y (OPCIONAL) WINNERS EN LA MEGA-CSV =========
  one_big <- NULL
  if (length(big_rows) > 0L) {
    one_big <- dplyr::bind_rows(big_rows)
    # Mete el rollup como bloque en la mega-CSV
    biglog <- .add_block(biglog, one_big, "one_big_rollup",
                         run_id, family = "__mixed__", config_tag = "__rollup__",
                         is_winner = FALSE, fold = NA_integer_)
  }
  
  if (isTRUE(pick_single_winner_per_family) && !is.null(one_big) && nrow(one_big) > 0) {
    cand <- one_big[one_big$is_finalist %in% TRUE, , drop = FALSE]
    if (nrow(cand) > 0) {
      metric_col <- switch(winner_metric,
                           robust_q95_mse  = "robust_q95_mse_final",
                           robust_mean_mse = "robust_mean_mse_final",
                           robust_max_mse  = "robust_max_mse_final")
      if (metric_col %in% names(cand)) {
        winners_df <- cand %>%
          dplyr::group_by(family) %>%
          dplyr::filter(.data[[metric_col]] == min(.data[[metric_col]], na.rm = TRUE)) %>%
          dplyr::slice(1) %>%
          dplyr::ungroup()
        # Incrusta winners como bloque especial
        biglog <- .add_block(biglog, winners_df, "family_winners",
                             run_id, family = "__mixed__", config_tag = "__winners__",
                             is_winner = TRUE, fold = NA_integer_)
      } else {
        warning(sprintf("Columna de métrica '%s' no encontrada para winners.", metric_col))
      }
    }
  }
  
  # ======================= UNA SOLA MEGA-CSV =============================
  if (length(biglog) == 0L) {
    progress_finalize()  # <- cierra barra también en salida temprana
    warning("No se recolectaron bloques; no hay datos para ALL_IN_ONE.csv")
    return(invisible(list(out_dir = root_out, all_in_one = NULL)))
  }
  
  
  all_in_one <- dplyr::bind_rows(biglog)
  # Parsea hiperparámetros desde .config_tag (si no existían como columnas)
  cfg_parsed <- dplyr::bind_rows(lapply(all_in_one$.config_tag, function(ct) {
    if (is.null(ct) || is.na(ct)) return(data.frame(ps=NA,mr=NA,a0=NA,am=NA,im=NA,t=NA,e=NA,seed=NA,stage=NA))
    .parse_config(ct)
  }))
  all_in_one <- dplyr::bind_cols(all_in_one, cfg_parsed)
  
  # Orden de columnas: primero trazabilidad
  front_cols <- c(".table",".run_id",".family",".config_tag",".is_winner",".fold",
                  "phase","grind_stage","coverage_hint",
                  "budget_gens","budget_pop","used_num_samples","used_bootstrapB",
                  "objective","scenario_mode",
                  "ps","mr","a0","am","im","t","e","seed","stage")
  rest_cols  <- setdiff(names(all_in_one), front_cols)
  all_in_one <- all_in_one[, c(intersect(front_cols, names(all_in_one)), rest_cols)]
  
  mkdirp(root_out)
  readr::write_csv(all_in_one, file.path(root_out, "ALL_IN_ONE.csv"))
  gz <- gzfile(file.path(root_out, "ALL_IN_ONE.csv.gz"), "wt")
  on.exit(close(gz), add = TRUE)
  readr::write_csv(all_in_one, gz)
  
  write_manifest(root_out, meta, extra = utils::head(all_in_one, 10))
  message(sprintf(
    "\nLISTO. Artefactos en: %s\n- ONE MEGA-CSV: %s (y .gz)\n",
    root_out,
    file.path(root_out, "ALL_IN_ONE.csv")
  ))
  progress_finalize()
  invisible(list(out_dir = root_out, all_in_one = all_in_one, winners = winners_df))
}



# -------- BIG LOG HELPERS (unified CSV) ---------------------------------
# (Se mantienen por compatibilidad. Úsalos si quieres un log detallado por tabla.)

# --- Internos: utilidades pequeñas para estampar contexto y columnas ----

.safe_cbind <- function(df, extra) {
  if (is.null(extra) || length(extra) == 0) return(df)
  ex <- as.data.frame(extra, stringsAsFactors = FALSE, check.names = FALSE)
  if (nrow(df) > 0 && nrow(ex) %in% c(0,1)) {
    # Recicla fila única de contexto a nrow(df)
    ex <- ex[rep(1, nrow(df)), , drop = FALSE]
    rownames(ex) <- NULL
  }
  cbind(df, ex, stringsAsFactors = FALSE)
}

# Parser de hiperparámetros desde config_tag (para trazabilidad completa)
.parse_config <- function(config_tag) {
  # Ejemplos de tags:
  # "ps80_mr0.18_a00.50_am1.00_im0.10_t2_e1_seed101"
  # "ps60_mr0.12_a01.00_am0.50_im0.05_t3_e2_seed202_STAGE2"
  as_num <- function(x) suppressWarnings(as.numeric(x))
  data.frame(
    ps    = as_num(sub(".*\\bps(\\d+).*", "\\1", config_tag)),
    mr    = as_num(sub(".*_mr([0-9.]+).*", "\\1", config_tag)),
    a0    = as_num(sub(".*_a0([0-9.]+).*", "\\1", config_tag)),
    am    = as_num(sub(".*_am([0-9.]+).*", "\\1", config_tag)),
    im    = as_num(sub(".*_im([0-9.]+).*", "\\1", config_tag)),
    t     = as_num(sub(".*_t(\\d+).*", "\\1", config_tag)),
    e     = as_num(sub(".*_e(\\d+).*", "\\1", config_tag)),
    seed  = as_num(sub(".*_seed(\\d+).*", "\\1", config_tag)),
    stage = as_num(sub(".*_STAGE(\\d+)$", "\\1", config_tag)),
    stringsAsFactors = FALSE, check.names = FALSE
  )
}

# Asegura que la tabla de escenarios tenga las columnas clave, rellenando con NA si faltan
.ensure_scenario_cols <- function(df) {
  need <- c("distribution","sample_size",
            "contamination_rate","outlier_scale_mad","contamination_type",
            "true_mean","scenario_mode",
            "estimator","mse","mse_q95","mse_max","bias","variance","mad","iqr")
  for (nm in need) if (!nm %in% names(df)) df[[nm]] <- NA
  df
}

# Asegura que la tabla de convergencia tenga las columnas clave
.ensure_convergence_cols <- function(df) {
  need <- c("gen","best_train","med_train","best_val","med_val")
  for (nm in need) if (!nm %in% names(df)) df[[nm]] <- NA
  df
}

# Construye un contexto enriquecido combinando:
# - lo que viene en 'context' (presupuestos, cobertura, fase, etc.)
# - lo que se pueda inferir del propio resultado (objective, scenario_mode) y del tag
.build_context <- function(df, table, run_id, family, config_tag, is_winner, fold, context) {
  # Inferencias básicas
  cfg <- .parse_config(config_tag)
  # Intento de deducir scenario_mode desde la propia tabla (si existe la col)
  scenemode_in_df <- df$scenario_mode[1] %||% NA
  # coverage_hint: por defecto "full" si scenario_mode == "full"; si no, "partial"
  inferred_cov <- if (!is.na(scenemode_in_df) && is.character(scenemode_in_df)) {
    ifelse(tolower(scenemode_in_df) == "full", "full", "partial")
  } else NA_character_
  base <- list(
    .table       = table,
    .run_id      = run_id,
    .family      = family,
    .config_tag  = config_tag,
    .is_winner   = is_winner,
    .fold        = as.integer(fold),
    coverage_hint = inferred_cov
  )
  # El 'context' que pase el llamador (budget_gens, budget_pop, used_num_samples, used_bootstrapB,
  # objective, scenario_mode, phase/grind_stage, etc.) sobrescribe inferencias si está presente.
  c(base, as.list(cfg), context %||% list())
}

.add_block <- function(biglog, df, table, run_id, family, config_tag,
                       is_winner = FALSE, fold = NA_integer_, context = NULL) {
  if (is.null(df) || !is.data.frame(df) || nrow(df) == 0L) return(biglog)
  
  # Normaliza tablas específicas (garantiza columnas clave para la mega-CSV)
  if (identical(table, "final_scenarios") || identical(table, "fold_scenarios")) {
    df <- .ensure_scenario_cols(df)
  } else if (identical(table, "final_convergence") || identical(table, "fold_convergence")) {
    df <- .ensure_convergence_cols(df)
  }
  
  # Construye contexto enriquecido e inyéctalo como columnas
  ctx <- .build_context(df, table, run_id, family, config_tag, is_winner, fold, context)
  df  <- .safe_cbind(df, ctx)
  
  biglog[[length(biglog) + 1L]] <- df
  biglog
}

# Extraer todo de un resultado de CV a filas largas
# 'context' permite estampar presupuestos/escenario/cobertura/fase:
#   list(
#     objective=..., scenario_mode=..., coverage_hint=..., phase="HPF1|HPF2|HALVING|FINAL",
#     grind_stage=1L, budget_gens=..., budget_pop=..., used_num_samples=..., used_bootstrapB=...
#   )
.collect_from_cv <- function(biglog, res_cv, run_id, family, config_tag,
                             is_winner = FALSE, context = NULL) {
  if (is.null(res_cv) || is.null(res_cv$final)) return(biglog)
  
  # Intenta extraer objective/scenario_mode del overall final si no vinieron en 'context'
  ov <- res_cv$final$overall
  if (is.data.frame(ov) && nrow(ov)) {
    context <- modifyList(
      list(
        objective    = ov$objective[1] %||% context$objective,
        scenario_mode= ov$scenario_mode[1] %||% context$scenario_mode
      ),
      context %||% list()
    )
  }
  
  biglog <- .add_block(biglog, res_cv$final$overall,        "final_overall",
                       run_id, family, config_tag, is_winner, fold = NA_integer_, context = context)
  biglog <- .add_block(biglog, res_cv$final$scenario_table, "final_scenarios",
                       run_id, family, config_tag, is_winner, fold = NA_integer_, context = context)
  biglog <- .add_block(biglog, res_cv$final$convergence,    "final_convergence",
                       run_id, family, config_tag, is_winner, fold = NA_integer_, context = context)
  
  fr_list <- res_cv$fold_results %||% list()
  for (k in seq_along(fr_list)) {
    fr <- fr_list[[k]]
    biglog <- .add_block(biglog, fr$overall,        "fold_overall",
                         run_id, family, config_tag, is_winner, fold = k, context = context)
    biglog <- .add_block(biglog, fr$scenario_table, "fold_scenarios",
                         run_id, family, config_tag, is_winner, fold = k, context = context)
    biglog <- .add_block(biglog, fr$convergence,    "fold_convergence",
                         run_id, family, config_tag, is_winner, fold = k, context = context)
  }
  biglog
}



# # =============================== FINAL RUN ===============================
# # Objetivo: ejecutar la corrida completa sobre TODAS las familias principales.
# # Resultados se guardan en "./Final/GA_UNIFIED_<timestamp>"
# 
out_final <- run_all_one_shot(
  families_to_run = c("normal"),

  # hiperparámetros GA (pool amplio, razonables para full run)
  pop_sizes       = c(80, 100),
  mutation_rates  = c(0.12, 0.18),
  init_alphas     = c(0.5, 1.0),
  alpha_mut_set   = c(0.5, 1.0),
  immigrant_rates = c(0.05, 0.10),
  t_sizes         = c(2L, 3L),
  elitism_set     = c(1L, 2L),
  seeds           = c(101, 202),

  # escenarios / CV
  sample_sizes    = c(300, 500, 1000, 2000, 5000),
  num_samples     = 100,
  generations_per_fold = 60,
  k_folds         = 3,
  final_retrain   = TRUE,

  # objetivo y penalizaciones
  objective       = "mixed",       # mezcla q95 + max (ver mix_w_* abajo)
  mix_w_q95       = 0.7,
  mix_w_max       = 0.3,
  lambda_instab_default = 0.15,
  bootstrap_B     = 300L,
  check_every     = 5L,
  patience        = 3L,
  min_delta       = 0.005,

  # ejecución
  use_parallel    = TRUE,
  out_root        = "./Final",

  # selección de ganador por familia (usa métricas *finales*)
  pick_single_winner_per_family = TRUE,
  winner_metric   = "robust_q95_mse",  # o "robust_mean_mse" / "robust_max_mse"
  suppress_intermediate_saves   = TRUE, # pon FALSE si quieres CSV por cada config/stage

  # ===== FASES ESTRICTAS DEL GRIND DE HP =====
  hp_strict = TRUE,

  # Fase 1 — minibatch de hiperparámetros + minibatch de escenarios
  hp1_frac = 0.25,      # ~25% del pool (o usa hp1_k)
  hp1_k    = NULL,
  hp1_gens = 10L,
  hp1_num_samples = NULL,      # por defecto 40% de num_samples
  hp1_bootstrap_B = NULL,      # por defecto ~33% de bootstrap_B
  hp1_minibatch_frac = 0.50,   # minibatch de escenarios (si modo=light)
  hp1_minibatch_min  = 10L,

  # Fase 2 — top ≈20 configs, más presupuesto, aún con minibatch de escenarios
  hp2_k    = 20L,
  hp2_gens = 20L,
  hp2_num_samples = NULL,      # por defecto 60% de num_samples
  hp2_bootstrap_B = NULL,      # por defecto 60% de bootstrap_B
  hp2_minibatch_frac = 0.50,
  hp2_minibatch_min  = 12L,

  # Pool que pasa a Fase 3 (Halving)
  hp3_pool_k = 10L,

  # ===== Fase 3 — HALVING (multi-fidelity, sin minibatch de escenarios) =====
  search_strategy   = "halving",
  eta               = 3,                 # reduce a ~1/3 en cada etapa
  finalists_per_family = 2,              # empuja 2 finalistas a presupuesto completo
  stage_gens_frac   = c(0.25, 0.60, 1.00),
  stage_pop_size    = c(40,   60,   NA), # NA -> usa max(pop_sizes)
  stage_num_samples = c(30,   60,   NA), # NA -> usa num_samples completo
  stage_bootstrap_B = c(60L,  100L, NA),

  # Nota: en Fase 3 el código fuerza escenarios FULL y minibatch_frac = NULL
  # (las líneas siguientes solo aplican si el modo light se activara en Fases 1/2)
  minibatch_frac = 0.40,
  minibatch_min  = 12L
)



# ================================ LIGHT RUN ==============================
# Objetivo: iterar rápido con buena señal. Halving + presupuestos recortados.
# Ideal para explorar knobs y validar integrales antes del FINAL RUN.
# Guarda en ./Light/GA_UNIFIED_<ts>

# out_light <- run_all_one_shot(
#   families_to_run = c("normal","lognormal"),
#   
#   # hiperparámetros GA (más chicos para ir ágil)
#   pop_sizes       = c(40, 60),
#   mutation_rates  = c(0.15, 0.20),
#   init_alphas     = c(0.5, 1.0),
#   alpha_mut_set   = c(0.8),
#   immigrant_rates = c(0.10),
#   t_sizes         = c(2L),
#   elitism_set     = c(1L),
#   seeds           = c(101),
#   
#   # escenarios / CV (presupuesto menor)
#   sample_sizes    = c(300, 1000, 2000),
#   num_samples     = 60,
#   generations_per_fold = 30,
#   k_folds         = 3,
#   final_retrain   = TRUE,     # consolidación final para estabilidad
#   
#   # objetivo y penalizaciones
#   objective       = "q95",
#   mix_w_q95       = 0.7,
#   mix_w_max       = 0.3,
#   lambda_instab_default = 0.15,
#   bootstrap_B     = 150L,
#   check_every     = 4L,
#   patience        = 3L,
#   min_delta       = 0.006,
#   
#   # ejecución
#   use_parallel    = TRUE,
#   out_root        = "./Light",
#   
#   pick_single_winner_per_family = TRUE,
#   winner_metric   = "robust_q95_mse",
#   suppress_intermediate_saves   = TRUE,
#   
#   # ===== FASES ESTRICTAS DEL GRIND DE HP (más chicas) =====
#   hp_strict = TRUE,
#   
#   # Fase 1 — 25% del pool, 10 gens, minibatch de escenarios
#   hp1_frac = 0.25,
#   hp1_k    = NULL,
#   hp1_gens = 10L,
#   hp1_num_samples = NULL,      # ~40% de 60 (=24)
#   hp1_bootstrap_B = NULL,      # ~33% de 150 (=50)
#   hp1_minibatch_frac = 0.50,
#   hp1_minibatch_min  = 10L,
#   
#   # Fase 2 — top ~20 (ajusta según pool), 20 gens, minibatch de escenarios
#   hp2_k    = 20L,
#   hp2_gens = 20L,
#   hp2_num_samples = NULL,      # ~60% de 60 (=40)
#   hp2_bootstrap_B = NULL,      # ~60% de 150 (=90, el código redondea)
#   hp2_minibatch_frac = 0.50,
#   hp2_minibatch_min  = 12L,
#   
#   # Pool a Fase 3
#   hp3_pool_k = 10L,
#   
#   # ===== Fase 3 — HALVING (full scenarios, sin minibatch) =====
#   search_strategy   = "halving",
#   eta               = 3,
#   finalists_per_family = 2,
#   stage_gens_frac   = c(0.30, 0.70, 1.00),
#   stage_pop_size    = c(30,   50,   NA),
#   stage_num_samples = c(24,   40,   NA),
#   stage_bootstrap_B = c(50L,  80L,  NA),
#   
#   # (Sólo usables en Fases 1/2 si el modo “light” se activa)
#   minibatch_frac = 0.50,
#   minibatch_min  = 10L
# )



